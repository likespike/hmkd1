{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1zG002Ybjgz23ixOhvCbU8ZyUsmHfT5XW","authorship_tag":"ABX9TyOXtY4ujSZaHCtjdRRfkbwT"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eyDKWnJtQv_E","executionInfo":{"status":"ok","timestamp":1688343268633,"user_tz":-540,"elapsed":24441,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"e9203d9b-71b1-4c04-dc00-006ca66c12ea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bMs6PvQlOzCZ"},"outputs":[],"source":["!pip install openai\n","!pip install gradio"]},{"cell_type":"markdown","source":["# 2.1 신경망과의 첫 만남"],"metadata":{"id":"HnUAi0jKOz9C"}},{"cell_type":"markdown","source":["**신경망 구조**\n","\n","Dense 층\n","- 모든 입력 뉴런과 출력 뉴런 사이에 연결된 완전히 연결된(fully connected) 층을 의미\n","- 각 입력 뉴런과 출력 뉴런 사이의 연결 가중치를 학습하고, 입력 신호에 가중치를 곱한 후 편향(bias)을 더하는 선형 변환(linear transformation)을 수행하고 이 선형 변환의 결과에 활성화 함수(activation function)를 적용하여 출력을 계산\n","- 예를 들어, Dense 층은 입력 벡터 [x₁, x₂, ..., xₙ]과 가중치 행렬 W, 편향 벡터 b가 주어졌을 때, 출력 벡터 [y₁, y₂, ..., yₘ]를 계산"],"metadata":{"id":"0bNdk1wRlkSD"}},{"cell_type":"markdown","source":["활성화 함수(Activation function)\n","\n","- 인공 신경망에서 각 뉴런의 출력을 결정하는 비선형 함수\n","- 활성화 함수는 입력 신호의 가중치 합과 편향을 적용한 후, 그 결과에 적용되어 다음 층으로 전달\n","- 인공 신경망에서 비선형성을 도입하고, 신경망의 복잡한 함수 근사(approximation) 능력을 향상시키는 것\n","- 인공 신경망은 여러 층의 연속된 선형 변환과 비선형 활성화 함수를 조합하여 복잡한 입력과 출력 관계를 학습\n","- 주요 활성화 함수\n","  - 시그모이드(Sigmoid) 함수:\n","    - 범위: 0과 1 사이\n","    - 주요 특징: 입력값을 확률로 해석할 수 있으며, 비선형 함수로서 미분 가능\n","    - 단점: 큰 입력값에 대해 그래디언트 소실 문제가 발생할 수 있음\n","  - 하이퍼볼릭 탄젠트(Tanh) 함수:\n","    - 범위: -1과 1 사이\n","    - 주요 특징: 시그모이드와 유사하게 비선형 함수이며, 원점을 중심으로 대칭\n","    - 단점: 여전히 큰 입력값에 대해 그래디언트 소실 문제가 발생할 수 있음\n","  - 렐루(ReLU, Rectified Linear Unit) 함수:\n","    - 범위: 0 이상의 입력에 대해 그대로 출력, 음수 입력에 대해 0 출력\n","    - 주요 특징: 계산이 간단하고 빠르며, 선형 영역으로 쉽게 학습 가능\n","    - 단점: 음수 입력에 대해 출력이 0이 되어 해당 뉴런이 활성화되지 않는 문제가 있음 (죽은 렐루 문제)\n","  - 소프트맥스(Softmax) 함수:\n","    - 범위: 0과 1 사이\n","    - 주요 특징: 다중 클래스 분류에 사용되며, 출력값을 확률 분포로 해석\n","    - 단점: 출력값의 합이 1이 되도록 정규화되어, 다른 출력값에 영향을 받을 수 있음"],"metadata":{"id":"9AI9BnGPlkx4"}},{"cell_type":"markdown","source":["# 1장 딥러닝이란 무엇인가?\n","## 1.1 인공 지능과 머신 러닝, 딥러닝\n","### 1.1.1 인공 지능\n","- 보통의 사람이 수행하는 지능적인 작업을 자동화하기 위한 연구 활동\n","- symbolic AI - 프로그래머가 명시적인 규칙을 줌(하드코딩된 규칙)\n","- 규칙과 데이터 -> 전통적인 프로그래밍 -> 해답 (데이터가 적절한 해답이 되게 하는 규칙, 즉 검퓨터 프로그램을 프로그래머가 작성함\n","### 1.1.2 머신 러닝\n","- 기계가 넣어준 데이러토 학습해서 룰을 만들어 내고 -> 그것 룰대로 예측함\n","- 데이터와 해답 -> 머신 러닝 -> 규칙\n","- 머신 러닝 시스템은 명시적으로 프로그램되는 것이 아니라 훈련된다\n","### 1.1.3 데이터에서 표현을 학습하기\n","-\n","### 1.1.4 딥러닝에서 '딥'이란 무엇일까?\n","- 1~2층의 얕은 학습기로 복잡한 문제를 풀기 어려움\n","- 사람의 신경망을 모방(벤치마킹)하는 것에 대해서 생각하기 시작함\n","- layer가 깊다는 의미임(연속된 층에 대한 의미)\n"],"metadata":{"id":"jTYhjn90SQ9P"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"],"metadata":{"id":"PQBHkyFkQm3c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689207874101,"user_tz":-540,"elapsed":5438,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"fa2cec60-7da0-477e-8e24-17018c4c2bc9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"code","source":["# 28 x 28 픽셀 사이즈가 60,000개 있는 것임\n","train_images.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5kDNSF-1i-Dy","executionInfo":{"status":"ok","timestamp":1687911894051,"user_tz":-540,"elapsed":301,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"dc8d1786-36b6-40c8-ab52-d2a37832e479"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["print(train_images[0].shape, '\\n')\n","train_images[59999]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lwsefr4Co642","executionInfo":{"status":"ok","timestamp":1689208151597,"user_tz":-540,"elapsed":9,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"5aebb50a-5ba4-444d-c4d1-76e7f7faaf89"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["(28, 28) \n","\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,  38,  48,  48,  22,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         62,  97, 198, 243, 254, 254, 212,  27,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  67,\n","        172, 254, 254, 225, 218, 218, 237, 248,  40,   0,  21, 164, 187,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  89, 219,\n","        254,  97,  67,  14,   0,   0,  92, 231, 122,  23, 203, 236,  59,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  25, 217, 242,\n","         92,   4,   0,   0,   0,   0,   4, 147, 253, 240, 232,  92,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 101, 255,  92,\n","          0,   0,   0,   0,   0,   0, 105, 254, 254, 177,  11,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 167, 244,  41,\n","          0,   0,   0,   7,  76, 199, 238, 239,  94,  10,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 192, 121,   0,\n","          0,   2,  63, 180, 254, 233, 126,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 190, 196,  14,\n","          2,  97, 254, 252, 146,  52,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 130, 225,  71,\n","        180, 232, 181,  60,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 130, 254, 254,\n","        230,  46,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   6,  77, 244, 254, 162,\n","          4,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0, 110, 254, 218, 254, 116,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0, 131, 254, 154,  28, 213,  86,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,  66, 209, 153,  19,  19, 233,  60,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0, 142, 254, 165,   0,  14, 216, 167,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,  90, 254, 175,   0,  18, 229,  92,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,  26, 229, 249, 176, 222, 244,  44,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  73, 193, 197, 134,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=uint8)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# [[ ]], - 이게 하나의 28 x 28 이미지임\n","train_images"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xGWkLo4CpxgO","executionInfo":{"status":"ok","timestamp":1689208170968,"user_tz":-540,"elapsed":8,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"8adad1af-b94c-4a6b-e95d-8b06a21dcbab"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       ...,\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["train_labels.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjaymGj9jMqJ","executionInfo":{"status":"ok","timestamp":1687830721613,"user_tz":-540,"elapsed":7,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"935bff66-1109-48b6-a091-242dc3e57fa8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000,)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["import numpy as np\n","\n","np.unique(train_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z6Q0916QltPi","executionInfo":{"status":"ok","timestamp":1687911897393,"user_tz":-540,"elapsed":335,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"977601fb-be63-4977-e2e3-a1040d41d13d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["test_images.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z6nTkwrylzeS","executionInfo":{"status":"ok","timestamp":1687831404913,"user_tz":-540,"elapsed":774,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"e24d9f29-0831-4957-d388-0ad5cba86d41"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(10000, 28, 28)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# unit8은 8개의 비트로 256개의 서로 다른 값을 표현\n","# 이미지 처리에서 많이 사용되는 데이터 형식 중 하나이며, 메모리 관리가 효율적이고 연산에도 효과적\n","\n","test_labels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZCnT-X6Sl1Uy","executionInfo":{"status":"ok","timestamp":1687831410208,"user_tz":-540,"elapsed":485,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"a0d823ce-baea-4b0c-8ec5-b921dfd3c785"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["#### 두 가지 방식\n","1. 순차적인 방식 (Sequential)\n","- relu - 선형 변환만으로 층을 쌓으면 효과가 없다. 비선형으로 해주어야 함, 선형을 relu함수에 싣는 것??\n","- softmax - 다중분류, 여러 개로 분류할 때 softmax를 활성화 함수로 쓴다\n","2. 함수 방식\n","\n"],"metadata":{"id":"hwtUNZSSmewD"}},{"cell_type":"markdown","source":["#### layers\n","- 신경망의 핵심 구성 요소\n","- 가장 기본이 되는 층은 dense layer (밀집층)임\n","- 층은 데이터를 위한 filter로 생각할 수 있음 (어떤 데이터가 들어가면 더 유용한 형태로 출력됨)\n","- 조금 더 구체적으로 층은 주어진 문제에 더 의미 있는 표현(representation)을 입력된 데이터로부터 추출함\n","- 대부분의 딥러닝은 간단한 층을 연결하여 구성되어 있고, 점진적으로 데이터를 정제하는 형태를 띠고 있음, 딥러닝 모델은 데이터 정제 필터(층)가 연속되어 있는 데이터 프로세싱을 위한 여과기와 같음\n","- 케라스의 레이어 keras.layers 패키지 안에는 다양한 층이 준비되어 있음,\n","\n","#### softmax\n","- 10개의 확률 점수가 들어 있는 배열(모두 더하면 1)을 반환"],"metadata":{"id":"uafEtwXVs-22"}},{"cell_type":"code","source":["from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","model = keras.Sequential([\n","    layers.Dense(512, activation='relu'),\n","    layers.Dense(10, activation='softmax')\n","])"],"metadata":{"id":"7wuJf7x2pEQs","executionInfo":{"status":"ok","timestamp":1689209783003,"user_tz":-540,"elapsed":4375,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["#### optimizer\n","- 성능을 향상키시기 위해 입력된 데이터를 기반으로 모델을 업데이트하는 메커니즘, 모델이 훈련하는 동안 가중치를 업데이트하는 알고리즘을 지정하는데 사용\n","    - rmsprop - 주로 경사 하강법이 사용되며, rmsprop는 경사 하강법 알고리즘 중 하나임\n","\n","#### loss function\n","- 훈련 데이터에서 모델의 성능을 측정하는 방법으로 모델이 옳은 방향으로 학습될 수 있도록 도와줌, optimizer의 기준이 되는 것이 손실 함수임\n","    - sparse_categorical_crossentropy - 분류 문제에서 주로 사용되는 손실 함수 중 하나, 정수 레이블을 가진 데이터에 적합함\n","\n","#### metrics\n","-"],"metadata":{"id":"poMY0JZot0sL"}},{"cell_type":"code","source":["model.compile(optimizer='rmsprop',\n","              loss='sparse_categorical_crossentropy',\n","              metrics='accuracy')"],"metadata":{"id":"Leu4kCGPl2dB","executionInfo":{"status":"ok","timestamp":1689209784507,"user_tz":-540,"elapsed":2,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# 훈련을 시작하기 전에 데이터를 모델에 맞는 크기로 바꾸고 모든 값을 0과 1 사이로 스케일을 조정함\n","# 신경망 모델에 입력으로 사용하기 위해서는 이미지 데이터를 1차원 형태로 변환해야 함\n","\n","train_images = train_images.reshape((60000, 28 * 28))    # 이미지 데이터를 1차원으로 펼치는 역할\n","train_images = train_images.astype('float32') / 255\n","test_images = test_images.reshape((10000, 28 * 28))\n","test_images = test_images.astype('float32') / 255"],"metadata":{"id":"KnqeNPDMo7rr","executionInfo":{"status":"ok","timestamp":1689209787087,"user_tz":-540,"elapsed":374,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# 변경 전\n","print(train_images[4].ndim)\n","train_images[4].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PBRNBnk5hMOR","executionInfo":{"status":"ok","timestamp":1687914224135,"user_tz":-540,"elapsed":7,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"0fd26917-e9cc-458a-990d-068dfb80b38f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n"]},{"output_type":"execute_result","data":{"text/plain":["(28, 28)"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["# 변경 후\n","print(train_images[4].ndim)\n","train_images[4].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qBSv2ASHhRQB","executionInfo":{"status":"ok","timestamp":1687914168910,"user_tz":-540,"elapsed":330,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"191118ff-138b-4381-f4b4-d8a5c95fd99b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"execute_result","data":{"text/plain":["(784,)"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["train_images.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wAJd-8KIqOe0","executionInfo":{"status":"ok","timestamp":1687832729281,"user_tz":-540,"elapsed":471,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"88c4623c-fd1a-471f-fea9-ac16e08e7b3c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 784)"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["model.fit(train_images, train_labels, epochs=5, batch_size=128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v5QACmcwpwiz","executionInfo":{"status":"ok","timestamp":1689209806319,"user_tz":-540,"elapsed":14012,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"23396377-2b82-42f5-b12d-92b3c2a02d4d"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","469/469 [==============================] - 8s 5ms/step - loss: 0.2623 - accuracy: 0.9231\n","Epoch 2/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.1056 - accuracy: 0.9692\n","Epoch 3/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0692 - accuracy: 0.9798\n","Epoch 4/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0497 - accuracy: 0.9851\n","Epoch 5/5\n","469/469 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9887\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f0b9f943ca0>"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["128*469"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K_CAJaREimf9","executionInfo":{"status":"ok","timestamp":1688619095746,"user_tz":-540,"elapsed":13,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"7b0d2e33-ddce-476c-b655-6a4dc326a870"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["60032"]},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["# 각각 784개의 특성을 가진 10,000개의 샘플 중 앞에서 10개의 샘플만 예측\n","# 다 더하면 1임\n","\n","test_digits = test_images[0:10]\n","predictions = model.predict(test_digits)\n","predictions[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Asxrv2gdp1Kw","executionInfo":{"status":"ok","timestamp":1689209806877,"user_tz":-540,"elapsed":588,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"f5237c85-cdb0-4b95-d86d-ef0fd6e7c0e9"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 75ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["array([5.7102866e-08, 4.8492161e-08, 8.4180119e-06, 1.8330717e-04,\n","       2.0008748e-11, 1.7467684e-08, 7.9927176e-12, 9.9980730e-01,\n","       2.4030660e-07, 6.2184728e-07], dtype=float32)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# argmax() - 주어진 배열 또는 시퀀스에서 가장 큰 값을 가지는 원소의 인덱스를 반환하는 함수\n","print(predictions[0].argmax())\n","predictions[0][7]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kEjEXFkQsS6M","executionInfo":{"status":"ok","timestamp":1689209806877,"user_tz":-540,"elapsed":4,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"caaa49f0-fa26-4065-ab97-5a648f25ab0d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["7\n"]},{"output_type":"execute_result","data":{"text/plain":["0.9998073"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# 테스트 데이터의 레이블과 맞는지 확인 (정답 확인)\n","test_labels[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZjC8mJMUwGRW","executionInfo":{"status":"ok","timestamp":1689209830532,"user_tz":-540,"elapsed":868,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"4326151b-bfb3-4cbe-b388-9921c9b1e115"},"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["7"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(f'테스트 정확도: {test_acc}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRY0cyTvr4v1","executionInfo":{"status":"ok","timestamp":1689210570454,"user_tz":-540,"elapsed":2226,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"ee78c5a5-81f6-49d5-c378-bbfb5e42d48e"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 1s 3ms/step - loss: 0.0667 - accuracy: 0.9800\n","테스트 정확도: 0.9800000190734863\n"]}]},{"cell_type":"markdown","source":["# 2.2 신경망을 위한 데이터 표현\n","#### 텐서\n","- 데이터를 위한 container, 숫자를 위한 컨테이너\n","- 텐서는 임의의 차원 개수를 가지는 행렬의 일반화된 모습\n","- 텐서에서는 dimension을 종종 axis라고 부름\n","\n","\n","\n"],"metadata":{"id":"kw6DKAPFy80E"}},{"cell_type":"markdown","source":["## 2.2.1 스칼라(랭크-0 텐서)\n","- 하나의 숫자만 담고 있는 텐서\n","- 0차원 = 축 개수인 rank-0"],"metadata":{"id":"LQ2Qghqb0S_k"}},{"cell_type":"code","source":["import numpy as np\n","x = np.array(12)\n","print(x.ndim)\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zdHT5_X3vchm","executionInfo":{"status":"ok","timestamp":1687834021641,"user_tz":-540,"elapsed":712,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"d4622f40-5008-4318-de16-6bfc8e10b139"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n"]},{"output_type":"execute_result","data":{"text/plain":["array(12)"]},"metadata":{},"execution_count":50}]},{"cell_type":"markdown","source":["## 2.2.2 벡터(랭크-1 텐서)\n","- 숫자의 배열, 딱 하나의 축을 가짐\n","- 5개의 원소를 가진 5차원, 5D 벡터임\n","- 5D 벡터는 하나의 축을 따라 5개의 차원을 가진 것이고 5D 텐서는 5개의 축을 가진 것임 (텐서의 각 축을 따라 여러 개의 차원을 가진 벡터가 놓일 수 있음)"],"metadata":{"id":"Bcbg-T4Z0nZE"}},{"cell_type":"code","source":["x = np.array([12, 3, 6, 14, 7])\n","print(x.ndim)\n","x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RysHX8zOvsZm","executionInfo":{"status":"ok","timestamp":1687834011369,"user_tz":-540,"elapsed":706,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"363f60c4-cf5a-48bd-8f6a-4306b1e10806"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1\n"]},{"output_type":"execute_result","data":{"text/plain":["array([12,  3,  6, 14,  7])"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["## 2.2.3 행렬(랭크-2 텐서)"],"metadata":{"id":"S_Magpxp0uum"}},{"cell_type":"code","source":["x = np.array([[5, 78, 2, 34, 0],\n","              [6, 79, 3, 35, 1],\n","              [7, 80, 4, 36, 2]])\n","x.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JEdh6vLZvscF","executionInfo":{"status":"ok","timestamp":1687834058810,"user_tz":-540,"elapsed":505,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"13facfc7-5cae-490b-c8b0-138cf0c874a2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2"]},"metadata":{},"execution_count":51}]},{"cell_type":"markdown","source":["## 2.2.4 랭크-3 텐서와 더 높은 랭크의 텐서"],"metadata":{"id":"K9fsq0EA1mTd"}},{"cell_type":"code","source":["x = np.array([[[5, 78, 2, 34, 0],\n","               [6, 79, 3, 35, 1],\n","               [7, 80, 4, 36, 2]],\n","               [[5, 78, 2, 34, 0],\n","               [6, 79, 3, 35, 1],\n","               [7, 80, 4, 36, 2]],\n","              [[5, 78, 2, 34, 0],\n","               [6, 79, 3, 35, 1],\n","               [7, 80, 4, 36, 2]]])\n","x.ndim"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pUp70xT5v92n","executionInfo":{"status":"ok","timestamp":1687834166740,"user_tz":-540,"elapsed":5,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"382e1e6f-d5af-4148-8197-cc4600e0171b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3"]},"metadata":{},"execution_count":53}]},{"cell_type":"markdown","source":["## 2.2.5 (텐서의 3개의) 핵심 속성\n","#### 축의 개수(랭크)\n","#### 크기(shape)\n","- 텐서의 각 축을 따라 얼마나 많은 차원이 있는지를 나타낸 파이썬의 tuple\n","#### 데이터 타입(파이썬 라이브러리에서는 보통 dtype이라고 부름)"],"metadata":{"id":"67BajR8Q2OfJ"}},{"cell_type":"markdown","source":["#### 이미지 데이터\n","- 3차원 이미지의 차원은 \"가로 픽셀 수 x 세로 픽셀 수 x 이미지 슬라이스 수\"로 표현\n","- 픽셀은 이미지를 구성하는 가장 작은 단위로, \"picture element\"의 줄임말이며 이미지를 표현하는 데 사용되는 점 또는 화소\n","- 흑백 이미지의 경우, 각 픽셀은 단일 색상 값을 가지며, 일반적으로 0부터 255까지의 범위로 표현. 0은 픽셀이 검은색에 가깝고, 255는 픽셀이 흰색에 가깝다.\n","- 컬러 이미지의 경우, 각 픽셀은 일반적으로 RGB(Red, Green, Blue) 값을 가지며 각각 빨강, 초록, 파랑의 강도를 나타내며, 0부터 255까지의 범위로 표현\n","- 강도의 조합에 따라 다양한 색상이 생성. 예를 들어, (255, 0, 0)은 빨간색, (0, 255, 0)은 초록색, (0, 0, 255)는 파란색\n","- 각 픽셀은 이미지의 위치에 따라 좌표로 식별. 가장 왼쪽 위 픽셀이 (0, 0)이며, 가로 방향으로 증가하면서 픽셀의 열 인덱스가 증가하고, 세로 방향으로 증가하면서 픽셀의 행 인덱스가 증가\n","- 이미지 처리 작업에서는 픽셀 단위의 조작이 중요하며, 픽셀 값을 수정하거나 분석하여 다양한 이미지 효과를 생성하거나 이미지에서 정보를 추출"],"metadata":{"id":"iu-7-j5CaAKq"}},{"cell_type":"code","source":["# 다섯 번째 이미지 데이터 - 픽셀당 0~255까지 표현함\n","from tensorflow.keras.datasets import mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","train_images[4]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"krMv3tZ0aaSu","executionInfo":{"status":"ok","timestamp":1689211992761,"user_tz":-540,"elapsed":554,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"cb3a64b2-439d-4543-d109-4314e5b6a5ba"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  55,\n","        148, 210, 253, 253, 113,  87, 148,  55,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  87, 232,\n","        252, 253, 189, 210, 252, 252, 253, 168,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   4,  57, 242, 252,\n","        190,  65,   5,  12, 182, 252, 253, 116,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  96, 252, 252, 183,\n","         14,   0,   0,  92, 252, 252, 225,  21,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0, 132, 253, 252, 146,  14,\n","          0,   0,   0, 215, 252, 252,  79,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0, 126, 253, 247, 176,   9,   0,\n","          0,   8,  78, 245, 253, 129,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,  16, 232, 252, 176,   0,   0,   0,\n","         36, 201, 252, 252, 169,  11,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,  22, 252, 252,  30,  22, 119, 197,\n","        241, 253, 252, 251,  77,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,  16, 231, 252, 253, 252, 252, 252,\n","        226, 227, 252, 231,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  55, 235, 253, 217, 138,  42,\n","         24, 192, 252, 143,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         62, 255, 253, 109,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         71, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         71, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","        106, 253, 252,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         45, 255, 253,  21,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0, 218, 252,  56,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,  96, 252, 189,  42,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,  14, 184, 252, 170,  11,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,  14, 147, 252,  42,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=uint8)"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["# binary color map - 이진 색상 맵, 흑백 이미지를 표시하는 데 사용됨, 0과 1 사이의 값을 흑백으로 표현하며, 0은 검은색에 가까워지고 1은 흰색에 가까워짐\n","# MNIST 데이터셋의 픽셀 값은 그레이스케일 값으로, 0은 흰색을 의미하고 255는 검은색을 의미\n","# 특정 시각화 라이브러리나 플랫폼에 따라서 0과 255의 색상 표현이 반대로 설정될 수 있으며 일부 라이브러리는 0을 검은색으로, 255를 흰색으로 표현\n","\n","import matplotlib.pyplot as plt\n","\n","digit = train_images[4]\n","plt.imshow(digit, cmap=plt.cm.binary)\n","plt.show()"],"metadata":{"id":"yiYcxUs8wV8v","colab":{"base_uri":"https://localhost:8080/","height":430},"executionInfo":{"status":"ok","timestamp":1689212027846,"user_tz":-540,"elapsed":629,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"325649ef-8031-486b-86b6-c3821658a812"},"execution_count":45,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["train_labels[4]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oOmi5HRybFBr","executionInfo":{"status":"ok","timestamp":1687912542687,"user_tz":-540,"elapsed":305,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"8cac1523-3d08-4423-d98f-e2b069ee3972"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## 넘파이로 텐서 조작하기\n","- 위에어 한 슬라이싱 연산에 대해 알아보기"],"metadata":{"id":"bTyy8DUPcLhy"}},{"cell_type":"code","source":["my_slice = train_images[10:100]\n","my_slice.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VcSb0meRbXLz","executionInfo":{"status":"ok","timestamp":1687912802168,"user_tz":-540,"elapsed":9,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"38fe0617-33d2-48ae-e586-b01829d6ad73"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(90, 28, 28)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["# 동일하지만 조금 더 자세한 표기법은 각 배열의 축을 따라 슬라이싱의 시작 인덱스와 마지막 인덱스를 지정하는 것\n","my_slice = train_images[10:100, :, :]\n","my_slice.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IKN9f6aucWUp","executionInfo":{"status":"ok","timestamp":1687912909475,"user_tz":-540,"elapsed":302,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"0db8d130-5918-4c1e-d3f8-076f2c3ff7e7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(90, 28, 28)"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["my_slice = train_images[10:100, 0:28, 0:28]\n","my_slice.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ANKQlPtQbVHh","executionInfo":{"status":"ok","timestamp":1687912927702,"user_tz":-540,"elapsed":8,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"c9df0583-0930-4b87-8ac3-635e117249c9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(90, 28, 28)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["# 이미지의 오른쪽 아래 14 x 14 픽셀을 선택하기\n","my_slice = train_images[:, 14:, 14:]"],"metadata":{"id":"5NhbJ2Jrc06p"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 정중앙에 위치한 14 x 14 픽셀 조각을 이미지에서 잘라 낼 때\n","my_slice = train_images[:, 7:-7, 7:-7]"],"metadata":{"id":"IOdv0R31c5aw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2.7 배치 데이터\n","- 일반적으로 딥러닝에서 사용하는 모든 데이터 텐서의 첫 번째 축(인덱스가 0부터 시작하므로 0번째 축)은 sample axis임 (이따금 sample dimension이라고도 부름)\n","- 딥러닝 모델은 한 번에 전체 데이터셋을 처리하지 않음, 그 대신 데이터를 작은 batch로 나눔, 구체적으로 말하면 MNIST 숫자 데이터에서 크가기 128인 배치 하나는 다음과 같음\n","- 배치 데이터를 다룰 때 첫 번째 축(0번 축)을 batch axis 또는 batch dimension이라고 부름"],"metadata":{"id":"zWdxxXAg6l1A"}},{"cell_type":"code","source":["batch = train_images[:128]"],"metadata":{"id":"nfvkP9rrc9XQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch = train_images[128:256]"],"metadata":{"id":"rzs9rQS7dLW1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.2.8 텐서의 실제 사례\n","#### 앞으로 사용할 데이터의 종류들\n","1. 백터 데이터\n","- (samples, features) 크기\n","- 각 샘플은 수치 속성, 특성, feature로 구성된 벡터<br><br>\n","\n","2. 시계열 데이터 또는 시퀀스(sequence) 데이터\n","- (samples, timesteps, features) 크기\n","- 각 샘플은 특성 벡터의 (길이가 timesteps인) 시퀀스<br><br>\n","\n","3. 이미지\n","-  (samples, heitht, width, channels) 또는 (samples, channels, height, width) 크기\n","- 각 샘플은 픽셀의 2D 격자고 각 픽셀은 수치 값(channel)의 벡터임<br><br>\n","\n","4. 동영상\n","- (samples, frames, height, width, channels) 또는 (samples, frames, channels, height, width) 크기\n","- 각 샘플은 이미지의 (길이가 frames인) 시퀀스임\n"],"metadata":{"id":"5_6Iv41p8DLt"}},{"cell_type":"markdown","source":["## 2.2.9 벡터 데이터\n","- 이런 데이터셋에서는 하나의 데이터 포인트가 벡터로 인코딩될 수 있으므로 배치 데이터는 랭크-2 텐서로 인코딩될 것임(즉, 벡터의 배열임)\n","- 여기에서 첫 번째 축은 샘플 축이고, 두 번째 축은 특성 축(feature axis)임\n","- (100,000, 3) - 100,000명의 사람 한 명 당 나이, 성별, 소득이라는 3개의 값을 가진 벡터로 구성됨\n","\n","## 2.2.10 시계열 데이터 또는 시쿼스 데이터\n","- 데이터에서 시간이 (또는 연속된 순서가) 중요할 때는 ㅣ간 축을 포함하여 랭크-3 텐서로 저장됨\n","- 각 샘플은 벡터의 시퀀스(랭크-3 텐서)로 인코딩되므로 배치 데이터는 랭크3 텐서로 인코딩 될 것임\n","\n","## 2.2.11 이미지 데이터\n","- 행이 먼저 나오므로 높이가 먼저임\n","- (128, 256, 256, 1) - batch, height, width, color_depth (흑백도 채널 1로 표현해주는 것이 관례임)\n","- (128, 256, 256, 3) - 컬러\n","- 위의 channel-last 방식과 달리 channel-first 방식도 있음 (128, 1, 256, 256)\n","- 케라스 API는 두 형식을 모두 지원하기는 함\n","- tensorflow.keras.backend.set_image_data_format() 함수를 사용하여 'channels-last' 또는 'channels_first'로 지정할 수 있음\n","- PyTorch는 기본적으로 채널 우선 방식을 사용함\n","\n","\n","## 2.2.12 비디오 데이터\n","- 비디오 데이터는 현실에서 랭크-5 텐서가 필요한 몇 안 되는 데이터 중 하나임\n","- (4, 240, 144, 256, 3) - 144 x256유튜브 비디오 클립(컬러 3)을 초당 4프레임으로 샘플링하면 240프레임, 이런 비디오 크립을 4개 가진 배치"],"metadata":{"id":"bmTxcK_k_YlV"}},{"cell_type":"markdown","source":["# 2.3 신경망의 톱니바퀴: 텐서 연산\n","- 컴퓨터 프로그램을 이진수의 입력을 처리하는 몇 개의 이항 연산(AND, OR, NOR 등)으로 표현할 수 있는 것처럼, 심층 신경망이 학습한 모든 변환을 수치 데이터 텐서에 적용하는 몇 종류의 텐서 연산(tensor operation)(또는 텐서 함수(tensor function))으로 나타낼 수 있음, 텐서 덧셈이나 텐서 곱센 등임\n","- 아래의 층은 행렬을 입력으로 받고 입력 텐서의 새로운 표현인 또 다른 행렬을 반환하는 함수처럼 해석할 수 있음 (W는 행렬이고, b는 벡터임- 둘 모두 층의 속성임)\n","- Dense 클래스의 객체를 Sequential 클래스에 추가할 때 Dense 객체의 build() 메서드가 호출되면서 가중치(커널) W와 편향 b가 생성됨, 각각 Dense 객체의 kernel고 bias 인스턴스 변수에 저장됨\n","- relu (rectified linear unit) - 입력이 0보다 크면 입력을 그대로 반환하고 0보다 작으면 0을 반환함\n","\n","```\n","keras.layers.Dense(512, activation='relu')\n","=\n","output = relu(dot(W, input) + b)\n","```\n","\n","- 과정\n","    - 입력 텐서와 텐서 W 사이의 점곱(dot)\n","    - 점곱으로 만들어진 행렬과 벡터 b 사이의 덧셈(+)\n","    - relu 연산, relu(x)는 max(x, 0)임\n","\n","<font color=red> dot이 맞는지 matmul이 맞는지</font>\n","네, 이해했습니다. matmul은 행렬 곱셈(matrix multiplication)을 의미하는 말로, 행렬 간의 곱셈을 나타냅니다.\n","\n","정확하게 말씀드리자면, dot 함수와 matmul 함수는 행렬 곱셈을 수행하는 데에는 비슷한 역할을 하지만, 다른 점이 있습니다.\n","\n","dot: dot 함수는 두 배열의 내적(inner product)을 계산하는 함수로, 행렬 곱셈 연산을 수행합니다. 그러나 다차원 배열의 경우에는 마지막 두 축을 이용하여 계산합니다. 따라서 dot 함수를 사용할 때에는 주의가 필요합니다.\n","\n","matmul: matmul 함수는 행렬 곱셈 연산을 수행하는 함수로, 두 배열의 행렬 곱셈을 계산합니다. 이 함수는 행렬의 곱셈 규칙에 따라 동작하며, 배열의 차원을 고려하여 행렬 곱셈을 수행합니다.\n","\n","따라서, 행렬 곱셈을 수행할 때에는 matmul 함수를 사용하는 것이 더 정확한 표현입니다. dot 함수도 일반적으로 행렬 곱셈에 사용될 수 있지만, 다차원 배열의 경우 축에 대한 이해와 주의가 필요합니다.\n","\n"],"metadata":{"id":"DOM3WZSKnJ65"}},{"cell_type":"markdown","source":["## 2.3.1 원소별 연산\n","- relu 함수와 덧셈은 원소별 연산(element-wise operation)임, 이 연산은 텐서에 있는 각 원소에 독립적으로 적용됨\n","- 파이썬으로 단순한 원소별 원산을 구현한다면 다음 relu 연산 구현처럼 for 반복문을 사용할 것임\n","- 사실 넘파이 배열을 다룰 때는 최적화된 넘파이 내장 함수로 이런 연산들을 처리할 수 있음, 넘파이는 BLAS(Basic Linear Algebra Subprogram) 구현에 복잡한 일들을 위임함, BLAS는 고도로 병렬화되고 효율적인 저수준의 텐서 조작 루틴이며, 전형적으로 Fortran이나 C 언어로 구현되어 있음\n","- 대표적인 BLAS 구현으로는 OpenBLAS, 인텔 MKL, ATLAS 등이 있음, 아나콘다 파이썬 배포판은 기본적으로 MKL 라이브러리를 사용함"],"metadata":{"id":"5ZR5Gt9XFyBd"}},{"cell_type":"code","source":["# relu 연산 구현해 보기\n","\n","def naive_relu(x):\n","    assert len(x.shape) == 2    # x는 랭크-2 넘파이 배열임, assert는 조건이 True인지 확인하고 아니면 AssertionError 예외를 발생시킴,\n","                                # 입력 텐서가 2차원이 아닌 경우 AssertionError 예외 발생시킴\n","    x = x.copy()    # 입력 텐서 자체를 바꾸지 않도록 복사\n","    for i in range(x.shape[0]):    # x의 각 원소에 대해 relu 연산을 수행함\n","        for j in range(x.shape[1]):\n","            x[i, j] = max(x[i, j], 0)    # x[i, j]와 0중에서 큰 값을 선택하여 해당 값을 x[i, j]에 대입함\n","    return x"],"metadata":{"id":"Ia4jNf7QdQ5F","executionInfo":{"status":"ok","timestamp":1689216403825,"user_tz":-540,"elapsed":539,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":57,"outputs":[]},{"cell_type":"code","source":["# 덧셈\n","\n","def naive_add(x, y):\n","    assert len(x.shape) == 2\n","    assert x.shape == y.shape\n","    x = x.copy()\n","    for i in range(x.shape[0]):\n","        for j in range(x.shape[1]):\n","            x[i, j] += y[i, j]\n","    return x"],"metadata":{"id":"StwSH_vUn1hv","executionInfo":{"status":"ok","timestamp":1689216404764,"user_tz":-540,"elapsed":6,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":58,"outputs":[]},{"cell_type":"code","source":["# 넘파이의 원소별 연산의 속도 테스트\n","\n","import numpy as np\n","import time\n","\n","x = np.random.random((20, 100))\n","y = np.random.random((20, 100))\n","\n","t0 = time.time()\n","for _ in range(1000):\n","    z = x + y    # 원소별 덧셈\n","    z = np.maximum(z, 0.)    # 원소별 렐루 함수\n","\n","print('걸린 시간: {0:.2f} s'.format(time.time() - t0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HYLdYbYSoPmv","executionInfo":{"status":"ok","timestamp":1689216294293,"user_tz":-540,"elapsed":430,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"531419c5-ca20-4581-a1e9-7fca0c14d714"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["걸린 시간: 0.01 s\n"]}]},{"cell_type":"code","source":["x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"inLW8qQtIx-R","executionInfo":{"status":"ok","timestamp":1689216331346,"user_tz":-540,"elapsed":704,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"bdbb8e96-fb37-447a-e5c8-0e02c586c06f"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.9712613 , 0.44257687, 0.78077125, ..., 0.41957247, 0.86615389,\n","        0.66765401],\n","       [0.87127235, 0.69348404, 0.86987532, ..., 0.78854096, 0.36117104,\n","        0.7844544 ],\n","       [0.69851203, 0.77126907, 0.20420459, ..., 0.2302845 , 0.67811009,\n","        0.38672672],\n","       ...,\n","       [0.7906334 , 0.89633849, 0.9922604 , ..., 0.1811573 , 0.13892768,\n","        0.08646957],\n","       [0.5568726 , 0.4701042 , 0.22618472, ..., 0.72749044, 0.27518881,\n","        0.05188421],\n","       [0.66431811, 0.90362235, 0.3622736 , ..., 0.31085748, 0.12561623,\n","        0.49914414]])"]},"metadata":{},"execution_count":56}]},{"cell_type":"markdown","source":["#### 이와 비슷하게 텐서플로 코드를 GPU에서 실행할 때 고도로 병렬화된 GPU 칩 구조를 최대로 활용할 수 있는 완전히 벡터화된 CUDA 구현을 통해 원소별(element-wise) 연산이 실행됨\n","- CUDA - GPU에서 벡터화된 연산을 수행할 수 있도록 지원하는 플랫폼"],"metadata":{"id":"Wi7enMtEJYgs"}},{"cell_type":"code","source":["t0 = time.time()\n","for _ in range(1000):\n","    z = naive_add(x, y)\n","    z = naive_relu(z)\n","\n","print('걸린 시간: {0:.2f} s'.format(time.time() - t0))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SZJZ3EHpo1BF","executionInfo":{"status":"ok","timestamp":1689216419490,"user_tz":-540,"elapsed":2385,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"946cfe89-3965-4965-f54c-b64e2e353844"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["걸린 시간: 1.97 s\n"]}]},{"cell_type":"markdown","source":["## 2.3.2 브로드캐스팅\n","- 앞서 살펴본 단순한 덧셈 구현인 naive_add는 동일한 크기의 랭크-2 텐서만 지원함, 하지만 이전에 보았던 Dense 층에서는 랭크-2 텐서와 벡테를 더했음, 크기가 다른 두 텐서가 더해질 수 있었던 것은 작은 텐서가 큰 텐서의 크기에 맞추어 broadcasting되기 때문임\n","    - 큰 텐서의 ndim에 맞도록 작은 텐서에 (브로드캐스팅 축이라고 부르는) 축이 추가됨\n","    - 작은 텐서가 새 축을 따라서 큰 텐서의 크기에 맞도록 반복됨"],"metadata":{"id":"Z9leHTE7KBm0"}},{"cell_type":"code","source":["X = np.random.random((32, 10))    # X는 크기가 (32, 10)인 랜덤한 행렬임\n","print(X[0:3])\n","y = np.random.random((10,))    # y는 크기가 (10,)인 랜덤한 벡터임\n","y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"94B46ClErNpf","executionInfo":{"status":"ok","timestamp":1689216768919,"user_tz":-540,"elapsed":572,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"d9971333-0cc3-4ea6-d43b-a7f7174c79bc"},"execution_count":60,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.35082383 0.42369023 0.11532645 0.41143435 0.01815763 0.86869687\n","  0.15440851 0.51408145 0.82844421 0.31492807]\n"," [0.59762869 0.66315538 0.01905385 0.44743321 0.22395223 0.52114084\n","  0.85293343 0.78251084 0.11775759 0.43156906]\n"," [0.44808804 0.08509203 0.78300732 0.53810253 0.84774072 0.54452786\n","  0.35390247 0.87744809 0.18350484 0.09463697]]\n"]},{"output_type":"execute_result","data":{"text/plain":["array([0.71344549, 0.17329613, 0.78427044, 0.74365735, 0.63780701,\n","       0.48780204, 0.51346158, 0.43357057, 0.02597302, 0.24146281])"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","source":["# np.reshape(y, (10, 1))\n","# y.reshape(10,1)\n","y = np.expand_dims(y, axis=0)\n","y"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WlM3IXGJrgeQ","executionInfo":{"status":"ok","timestamp":1689217073609,"user_tz":-540,"elapsed":557,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"49f981ac-06be-4a4f-eacb-dc6ed857dd49"},"execution_count":62,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0.27032791, 0.1314828 , 0.05537432, 0.30159863, 0.26211815,\n","         0.45614057, 0.68328134, 0.69562545, 0.28351885, 0.37992696]]])"]},"metadata":{},"execution_count":62}]},{"cell_type":"code","source":["np.concatenate([y]*32, axis=0)[:3]    # 축 0을 따라 y를 32번 반복하여 크기가 (32,10)인 Y를 얻음"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OVdcbE6AsRld","executionInfo":{"status":"ok","timestamp":1689217074168,"user_tz":-540,"elapsed":6,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"c30bdaab-f02c-4c46-b57a-78eccf404a54"},"execution_count":63,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0.27032791, 0.1314828 , 0.05537432, 0.30159863, 0.26211815,\n","         0.45614057, 0.68328134, 0.69562545, 0.28351885, 0.37992696]],\n","\n","       [[0.27032791, 0.1314828 , 0.05537432, 0.30159863, 0.26211815,\n","         0.45614057, 0.68328134, 0.69562545, 0.28351885, 0.37992696]],\n","\n","       [[0.27032791, 0.1314828 , 0.05537432, 0.30159863, 0.26211815,\n","         0.45614057, 0.68328134, 0.69562545, 0.28351885, 0.37992696]]])"]},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["import numpy as np\n","\n","np.random.seed(0)\n","X = np.random.random((32, 10))    # X는 크기가 (32, 10)인 랜덤한 행렬임\n","y = np.random.random((10,))    # y는 크기가 (10,)인 랜덤한 벡터임\n","\n","# 먼저 y에 비어 있는 첫 번째 축을 추가하여 크기를(1, 10)으로 만듦\n","y = np.expand_dims(y, axis=0)    # 이제 y의 크기는 (1,10)임\n","\n","# 그런 다음 y를 이 축에 32번 반복하면 텐서 Y의 크기는 (32, 10)이 됨\n","Y = np.concatenate([y]*32, axis=0)    # 축 0을 따라 y를 32번 반복하여 크기가 (32, 10)인 Y를 얻음"],"metadata":{"id":"j-Bv_0WsqAFK","executionInfo":{"status":"ok","timestamp":1689217066656,"user_tz":-540,"elapsed":396,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":61,"outputs":[]},{"cell_type":"code","source":["(X + Y)[:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"23NArsjBunFm","executionInfo":{"status":"ok","timestamp":1689217112785,"user_tz":-540,"elapsed":385,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"591bb7fb-4e69-4325-821a-2505fc83bb30"},"execution_count":64,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.81914141, 0.84667217, 0.6581377 , 0.84648182, 0.68577295,\n","        1.10203468, 1.12086855, 1.58739845, 1.24718161, 0.76336847],\n","       [1.06205294, 0.66037772, 0.62341888, 1.22719527, 0.33315421,\n","        0.54326987, 0.70349973, 1.52824529, 1.0616756 , 1.2499391 ],\n","       [1.24894625, 0.93064136, 0.51685368, 1.08212781, 0.38039258,\n","        1.09606159, 0.82663462, 1.64029436, 0.80536717, 0.7945889 ]])"]},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["def naive_add_matrix_and_vector(x, y):\n","    assert len(x.shape) == 2    # x는 랭크-2 넘파이 배열임, assert - 주어진 조건이 True인지 확인, False면 AssertionError 예외를 발생시킴\n","    assert len(y.shape) == 1    # y는 넘파이 벡터임\n","    assert x.shape[1] == y.shape[0]\n","    x = x.copy()\n","    for i in range(x.shape[0]):\n","        for j in range(x.shape[1]):\n","            x[i, j] += y[j]\n","    return x"],"metadata":{"id":"w9XwagZUrLbY","executionInfo":{"status":"ok","timestamp":1689217126871,"user_tz":-540,"elapsed":567,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":66,"outputs":[]},{"cell_type":"code","source":["np.random.seed(0)\n","X = np.random.random((32, 10))    # X는 크기가 (32, 10)인 랜덤한 행렬임\n","y = np.random.random((10,))\n","\n","naive_add_matrix_and_vector(X, y)[:3]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7jlvO-94tEe-","executionInfo":{"status":"ok","timestamp":1689217128830,"user_tz":-540,"elapsed":7,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"b49a581b-d358-4e63-e214-810f51b7f16f"},"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.81914141, 0.84667217, 0.6581377 , 0.84648182, 0.68577295,\n","        1.10203468, 1.12086855, 1.58739845, 1.24718161, 0.76336847],\n","       [1.06205294, 0.66037772, 0.62341888, 1.22719527, 0.33315421,\n","        0.54326987, 0.70349973, 1.52824529, 1.0616756 , 1.2499391 ],\n","       [1.24894625, 0.93064136, 0.51685368, 1.08212781, 0.38039258,\n","        1.09606159, 0.82663462, 1.64029436, 0.80536717, 0.7945889 ]])"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["import numpy as np\n","\n","x = np.random.random((64, 3, 32, 10))\n","y = np.random.random((32, 10))\n","z = np.maximum(x, y)    # broadcasting 지원\n","print(z.shape)\n","z"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65lwuw5pMIik","executionInfo":{"status":"ok","timestamp":1689217243329,"user_tz":-540,"elapsed":921,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"4028c597-296a-48e0-bbc6-e3e2495d3602"},"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["(64, 3, 32, 10)\n"]},{"output_type":"execute_result","data":{"text/plain":["array([[[[0.89743848, 0.95535273, 0.73150291, ..., 0.3167547 ,\n","          0.82434507, 0.8987299 ],\n","         [0.2800033 , 0.53604373, 0.93231013, ..., 0.94090242,\n","          0.5184744 , 0.97367147],\n","         [0.78150838, 0.62743908, 0.43535072, ..., 0.81717697,\n","          0.09011865, 0.41097574],\n","         ...,\n","         [0.92851422, 0.99317801, 0.20640299, ..., 0.09716652,\n","          0.48273796, 0.46842544],\n","         [0.84563625, 0.84782582, 0.96115052, ..., 0.53178824,\n","          0.97572453, 0.81440422],\n","         [0.20363616, 0.86655957, 0.65649483, ..., 0.51224803,\n","          0.8079704 , 0.07494415]],\n","\n","        [[0.75577711, 0.38262023, 0.35963488, ..., 0.07074974,\n","          0.77455171, 0.45501827],\n","         [0.26604432, 0.5768708 , 0.60521004, ..., 0.94090242,\n","          0.89203822, 0.97367147],\n","         [0.75712366, 0.76505506, 0.71743226, ..., 0.67184612,\n","          0.10374201, 0.14406935],\n","         ...,\n","         [0.92851422, 0.88119613, 0.70230281, ..., 0.84863332,\n","          0.71664341, 0.56655713],\n","         [0.92258844, 0.04504445, 0.96115052, ..., 0.95453135,\n","          0.88985202, 0.46815506],\n","         [0.7220854 , 0.86655957, 0.6170416 , ..., 0.33467475,\n","          0.51717199, 0.51808541]],\n","\n","        [[0.84139555, 0.38262023, 0.54131156, ..., 0.05086361,\n","          0.77455171, 0.90995083],\n","         [0.58974813, 0.6232111 , 0.45729069, ..., 0.94090242,\n","          0.76041454, 0.97367147],\n","         [0.75712366, 0.62743908, 0.60663297, ..., 0.67184612,\n","          0.49227307, 0.73041364],\n","         ...,\n","         [0.92851422, 0.88119613, 0.73577897, ..., 0.01788909,\n","          0.7567533 , 0.949177  ],\n","         [0.80873677, 0.7038324 , 0.96115052, ..., 0.53178824,\n","          0.85609014, 0.47410501],\n","         [0.27806842, 0.86655957, 0.26816588, ..., 0.75634785,\n","          0.51717199, 0.87317938]]],\n","\n","\n","       [[[0.63878664, 0.38262023, 0.59461761, ..., 0.4186955 ,\n","          0.9144869 , 0.97589529],\n","         [0.75275668, 0.53604373, 0.97194958, ..., 0.94090242,\n","          0.83648398, 0.97367147],\n","         [0.75712366, 0.62743908, 0.56004584, ..., 0.67184612,\n","          0.40819695, 0.71548047],\n","         ...,\n","         [0.92851422, 0.88119613, 0.8751547 , ..., 0.85746787,\n","          0.28498841, 0.47495342],\n","         [0.79280398, 0.22657054, 0.96115052, ..., 0.80896127,\n","          0.8684829 , 0.57644321],\n","         [0.97097869, 0.86655957, 0.61525835, ..., 0.10202925,\n","          0.90548458, 0.44694151]],\n","\n","        [[0.63878664, 0.38262023, 0.90341845, ..., 0.57247065,\n","          0.77455171, 0.51680893],\n","         [0.27809905, 0.53604373, 0.18974634, ..., 0.94090242,\n","          0.5184744 , 0.97367147],\n","         [0.75712366, 0.93544058, 0.27548886, ..., 0.67184612,\n","          0.46408047, 0.22344799],\n","         ...,\n","         [0.92851422, 0.88119613, 0.20640299, ..., 0.97168814,\n","          0.08189686, 0.82811735],\n","         [0.74290398, 0.92054595, 0.96115052, ..., 0.53178824,\n","          0.2863695 , 0.62674823],\n","         [0.84480449, 0.88216237, 0.48328077, ..., 0.56823566,\n","          0.84525031, 0.76744562]],\n","\n","        [[0.63878664, 0.8174756 , 0.79687464, ..., 0.0758672 ,\n","          0.81362726, 0.3108354 ],\n","         [0.20955992, 0.67877866, 0.64722777, ..., 0.94090242,\n","          0.5184744 , 0.97367147],\n","         [0.75712366, 0.62743908, 0.27548886, ..., 0.94601826,\n","          0.8661281 , 0.9127827 ],\n","         ...,\n","         [0.92851422, 0.88119613, 0.68675739, ..., 0.9889426 ,\n","          0.70646237, 0.18532708],\n","         [0.52299368, 0.54512516, 0.96115052, ..., 0.87778317,\n","          0.32267258, 0.34399251],\n","         [0.54698979, 0.86655957, 0.37978563, ..., 0.49024622,\n","          0.85121989, 0.12185465]]],\n","\n","\n","       [[[0.63878664, 0.66074777, 0.31142463, ..., 0.18544677,\n","          0.8787207 , 0.22825317],\n","         [0.20955992, 0.53604373, 0.18974634, ..., 0.94090242,\n","          0.5184744 , 0.97367147],\n","         [0.75712366, 0.62743908, 0.73450525, ..., 0.82744252,\n","          0.58628447, 0.30942092],\n","         ...,\n","         [0.92851422, 0.88119613, 0.88541663, ..., 0.20805939,\n","          0.34802438, 0.18532708],\n","         [0.40449582, 0.80542701, 0.96115052, ..., 0.53178824,\n","          0.2863695 , 0.65977425],\n","         [0.99306939, 0.86655957, 0.85077433, ..., 0.22675052,\n","          0.51717199, 0.10449444]],\n","\n","        [[0.63878664, 0.69040272, 0.31142463, ..., 0.22982641,\n","          0.86939765, 0.41815737],\n","         [0.20955992, 0.58273671, 0.82078368, ..., 0.94090242,\n","          0.83664092, 0.97367147],\n","         [0.76939686, 0.82506494, 0.91177017, ..., 0.67184612,\n","          0.69504871, 0.9013193 ],\n","         ...,\n","         [0.92851422, 0.88119613, 0.67126592, ..., 0.06063981,\n","          0.36832551, 0.19837632],\n","         [0.59358871, 0.3238117 , 0.96115052, ..., 0.98238639,\n","          0.48385827, 0.43578806],\n","         [0.48336245, 0.86655957, 0.98522051, ..., 0.65730845,\n","          0.99316357, 0.95325418]],\n","\n","        [[0.66036031, 0.7833693 , 0.7840414 , ..., 0.97629946,\n","          0.88241582, 0.22825317],\n","         [0.80656909, 0.53604373, 0.81002575, ..., 0.94090242,\n","          0.5184744 , 0.97367147],\n","         [0.75712366, 0.62743908, 0.35656775, ..., 0.67184612,\n","          0.73522776, 0.5704626 ],\n","         ...,\n","         [0.92851422, 0.88119613, 0.85882904, ..., 0.2915038 ,\n","          0.20165732, 0.9379685 ],\n","         [0.50428239, 0.43558387, 0.96115052, ..., 0.53178824,\n","          0.2863695 , 0.63685742],\n","         [0.49774739, 0.86655957, 0.44683956, ..., 0.02982458,\n","          0.69137193, 0.07494415]]],\n","\n","\n","       ...,\n","\n","\n","       [[[0.63878664, 0.38262023, 0.31142463, ..., 0.61183364,\n","          0.81140692, 0.23031701],\n","         [0.88330404, 0.53604373, 0.29711393, ..., 0.94090242,\n","          0.58747607, 0.97367147],\n","         [0.75712366, 0.62743908, 0.44849153, ..., 0.71923583,\n","          0.93245206, 0.37723579],\n","         ...,\n","         [0.92851422, 0.88119613, 0.31379506, ..., 0.80779787,\n","          0.08189686, 0.86454085],\n","         [0.67301735, 0.23952215, 0.96115052, ..., 0.53178824,\n","          0.66126779, 0.57834433],\n","         [0.37695401, 0.86655957, 0.7863008 , ..., 0.84007436,\n","          0.51717199, 0.07494415]],\n","\n","        [[0.63878664, 0.38262023, 0.31142463, ..., 0.85329274,\n","          0.77455171, 0.39001879],\n","         [0.84918136, 0.81419695, 0.56004957, ..., 0.94090242,\n","          0.5184744 , 0.97367147],\n","         [0.75712366, 0.62743908, 0.60988636, ..., 0.92138703,\n","          0.98573777, 0.6123326 ],\n","         ...,\n","         [0.92851422, 0.96498742, 0.86544446, ..., 0.90594804,\n","          0.85123779, 0.60725156],\n","         [0.7864133 , 0.14501465, 0.96115052, ..., 0.53178824,\n","          0.94687694, 0.34779747],\n","         [0.20363616, 0.86655957, 0.83554325, ..., 0.23469555,\n","          0.9660804 , 0.53295017]],\n","\n","        [[0.67683986, 0.38262023, 0.31142463, ..., 0.71418662,\n","          0.77455171, 0.22825317],\n","         [0.74425786, 0.9748178 , 0.29868499, ..., 0.95005328,\n","          0.72890017, 0.97367147],\n","         [0.8791256 , 0.64878772, 0.27548886, ..., 0.67184612,\n","          0.05460093, 0.76081108],\n","         ...,\n","         [0.92851422, 0.88119613, 0.22942529, ..., 0.52438805,\n","          0.5616191 , 0.99583823],\n","         [0.40449582, 0.37174376, 0.96115052, ..., 0.99585226,\n","          0.51324096, 0.58457279],\n","         [0.53924561, 0.86655957, 0.38233161, ..., 0.40983072,\n","          0.51717199, 0.2912143 ]]],\n","\n","\n","       [[[0.63878664, 0.74803705, 0.60848825, ..., 0.65912301,\n","          0.77455171, 0.61240552],\n","         [0.55970901, 0.66883365, 0.86992003, ..., 0.94090242,\n","          0.5184744 , 0.97367147],\n","         [0.75712366, 0.62743908, 0.92848476, ..., 0.67184612,\n","          0.91197776, 0.55825886],\n","         ...,\n","         [0.92851422, 0.88119613, 0.56156306, ..., 0.35196147,\n","          0.90012549, 0.51892355],\n","         [0.40449582, 0.79723672, 0.96115052, ..., 0.53178824,\n","          0.2863695 , 0.73970703],\n","         [0.27028757, 0.86655957, 0.26816588, ..., 0.79145556,\n","          0.95179995, 0.4071154 ]],\n","\n","        [[0.63878664, 0.75938423, 0.65763403, ..., 0.79080612,\n","          0.77455171, 0.25124795],\n","         [0.20955992, 0.9682718 , 0.59677129, ..., 0.94090242,\n","          0.5184744 , 0.97367147],\n","         [0.75712366, 0.95333328, 0.71311219, ..., 0.99697112,\n","          0.87860231, 0.67750492],\n","         ...,\n","         [0.92851422, 0.88119613, 0.79378316, ..., 0.54629505,\n","          0.50294689, 0.65015316],\n","         [0.63150797, 0.57766672, 0.96115052, ..., 0.53178824,\n","          0.55451803, 0.13878611],\n","         [0.27637828, 0.86655957, 0.26816588, ..., 0.31289167,\n","          0.90683266, 0.90162816]],\n","\n","        [[0.63878664, 0.48799715, 0.31142463, ..., 0.91409791,\n","          0.77455171, 0.71946715],\n","         [0.37660624, 0.60205987, 0.90814293, ..., 0.94090242,\n","          0.5184744 , 0.97367147],\n","         [0.88921331, 0.62743908, 0.40449667, ..., 0.67184612,\n","          0.14405559, 0.72307041],\n","         ...,\n","         [0.92851422, 0.88119613, 0.80500609, ..., 0.65865888,\n","          0.69185497, 0.55665977],\n","         [0.90144708, 0.58967012, 0.96115052, ..., 0.58978081,\n","          0.50967147, 0.62782527],\n","         [0.40155199, 0.88181222, 0.26816588, ..., 0.30706851,\n","          0.51717199, 0.45998987]]],\n","\n","\n","       [[[0.63878664, 0.54677054, 0.61747307, ..., 0.96410373,\n","          0.77455171, 0.49919427],\n","         [0.9229889 , 0.69236248, 0.43459263, ..., 0.94090242,\n","          0.78991059, 0.97367147],\n","         [0.94987498, 0.62743908, 0.78208181, ..., 0.67545666,\n","          0.54362858, 0.34969389],\n","         ...,\n","         [0.92851422, 0.88119613, 0.29705791, ..., 0.91860754,\n","          0.33963873, 0.18532708],\n","         [0.84784953, 0.08965312, 0.96115052, ..., 0.53178824,\n","          0.73929159, 0.39817664],\n","         [0.6438101 , 0.93557213, 0.99554495, ..., 0.02805513,\n","          0.51717199, 0.54827741]],\n","\n","        [[0.63878664, 0.38262023, 0.6099637 , ..., 0.47782145,\n","          0.77455171, 0.79386363],\n","         [0.35801982, 0.7407026 , 0.18974634, ..., 0.94090242,\n","          0.5184744 , 0.97367147],\n","         [0.95940887, 0.75635695, 0.27548886, ..., 0.84391503,\n","          0.18639991, 0.14406935],\n","         ...,\n","         [0.92851422, 0.88119613, 0.20640299, ..., 0.04558467,\n","          0.08189686, 0.59048412],\n","         [0.40449582, 0.08581445, 0.96115052, ..., 0.53178824,\n","          0.90565745, 0.44261816],\n","         [0.58468504, 0.86655957, 0.48475579, ..., 0.29169854,\n","          0.51717199, 0.34000188]],\n","\n","        [[0.63878664, 0.74132214, 0.31142463, ..., 0.56690341,\n","          0.84609789, 0.64387213],\n","         [0.79371671, 0.76372345, 0.18974634, ..., 0.94090242,\n","          0.97765647, 0.97367147],\n","         [0.94751912, 0.62743908, 0.7256392 , ..., 0.67184612,\n","          0.61942318, 0.83472246],\n","         ...,\n","         [0.92851422, 0.88119613, 0.33446648, ..., 0.70646884,\n","          0.88379525, 0.72856172],\n","         [0.86412757, 0.78617209, 0.96115052, ..., 0.73739778,\n","          0.2863695 , 0.90420662],\n","         [0.9645851 , 0.86655957, 0.56969739, ..., 0.05665234,\n","          0.52617134, 0.85210522]]]])"]},"metadata":{},"execution_count":73}]},{"cell_type":"markdown","source":["## 2.3.3 텐서 곱셈\n","- 텐서 곱셈(tensor product)\n","- 점곱(dot product)"],"metadata":{"id":"pDKi8YJewVT6"}},{"cell_type":"code","source":["x = np.random.random((32,))\n","y = np.random.random((32,))\n","z = np.dot(x, y)"],"metadata":{"id":"4ApncKpaM4zM","executionInfo":{"status":"ok","timestamp":1689217615302,"user_tz":-540,"elapsed":530,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":76,"outputs":[]},{"cell_type":"code","source":["# 두 벡터의 점곱\n","def naive_vector_dot(x, y):\n","    assert len(x.shape) == 1    # x와 y는 넘파이 벡터임\n","    assert len(y.shape) == 1\n","    assert x.shape[0] == y.shape[0]\n","    z = 0.\n","    for i in range(x.shape[0]):\n","        z += x[i] * y[i]\n","    return z\n","\n","naive_vector_dot(x, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p8mPwIomNBLr","executionInfo":{"status":"ok","timestamp":1689217628546,"user_tz":-540,"elapsed":571,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"529d5cee-cac5-424d-8af2-7f3d2e2a1cad"},"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9.411457394459598"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["# 행렬 x와 벡터 y 사이에서의 점곱\n","\n","x = np.random.random((32,32))\n","y = np.random.random((32,))\n","z = np.dot(x, y)\n","\n","def naive_matrix_vector_dot(x, y):\n","    assert len(x.shape) == 2    # x는 넘파이 행렬\n","    assert len(y.shape) == 1    # y는 넘파이 벡터\n","    assert x.shape[1] == y.shape[0]    # x의 두 번째 차원이 y의 첫 번째 차원과 같아야 함\n","    z = np.zeros(x.shape[0])    # 이 연산은 x의 행과 같은 크기의 0이 채워진 벡터를 만듦\n","    for i in range(x.shape[0]):\n","        for j in range(x.shape[1]):\n","            z[i] += x[i, j] * y[j]\n","    return z\n","\n","naive_matrix_vector_dot(x, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pLqEzOjJNV6D","executionInfo":{"status":"ok","timestamp":1689217691087,"user_tz":-540,"elapsed":391,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"5c2e229a-16cb-43f4-e943-6d1000273110"},"execution_count":81,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([7.72112885, 7.14441927, 8.12131892, 8.7525412 , 8.87985878,\n","       6.73984011, 9.82387497, 7.8595803 , 8.25631385, 8.80205215,\n","       8.89480253, 6.49444094, 8.62684574, 6.75220652, 9.1774624 ,\n","       8.22050274, 6.77211766, 7.4566165 , 6.91477739, 7.66496916,\n","       8.58415102, 9.44199225, 8.2678074 , 7.26099562, 6.75365396,\n","       8.02546959, 8.24500709, 9.22308719, 7.18590635, 9.60638426,\n","       7.7649222 , 8.27077238])"]},"metadata":{},"execution_count":81}]},{"cell_type":"markdown","source":["- 두 텐서 중 하나라도 ndim이 1보다 크면 dot 연산에 교환 법칙이 성립되지 않음, 다시 말하면 dot(x, y)와 dot(y, x)가 같지 않음 (벡터-벡터 점곱은 교환 법칙이 성립하지만 행렬-벡터, 행렬-행렬 점곱은 교환 법칙이 성립하지 않음)\n","- 물론 점곱은 임의의 축 개수를 가진 텐서에 일반화됨, 가장 일반적인 용도는 두 행렬 간의 점곱일 것임, x.shape[1] == y.shape[0]일 때 두 행렬 x와 y의 점곱(dot(x,y))이 성립되므 x의 행과 y의 열 사이 벡터 점곱으로 인해 (x.shape[0], y.shape[1])크기의 행렬이 됨 (아래 두 코드 참고)\n"],"metadata":{"id":"Iftj_ejSPkT0"}},{"cell_type":"code","source":["def naive_matrix_vector_dot(x, y):\n","    z = np.zeros(x.shape[0])\n","    for i in range(x.shape[0]):\n","        z[i] = naive_vector_dot(x[i, :], y)\n","    return z\n","\n","naive_matrix_vector_dot(x, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lj8E8lazO9TM","executionInfo":{"status":"ok","timestamp":1689217927925,"user_tz":-540,"elapsed":382,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"6415a691-3767-484a-9195-44ea5ff90361"},"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([7.72112885, 7.14441927, 8.12131892, 8.7525412 , 8.87985878,\n","       6.73984011, 9.82387497, 7.8595803 , 8.25631385, 8.80205215,\n","       8.89480253, 6.49444094, 8.62684574, 6.75220652, 9.1774624 ,\n","       8.22050274, 6.77211766, 7.4566165 , 6.91477739, 7.66496916,\n","       8.58415102, 9.44199225, 8.2678074 , 7.26099562, 6.75365396,\n","       8.02546959, 8.24500709, 9.22308719, 7.18590635, 9.60638426,\n","       7.7649222 , 8.27077238])"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":["x = np.random.random((32,32))\n","y = np.random.random((32,2))\n","\n","def naive_matrix_dot(x, y):\n","    assert len(x.shape) == 2\n","    assert len(y.shape) == 2\n","    assert x.shape[1] == y.shape[0]\n","    z = np.zeros((x.shape[0], y.shape[1]))\n","    for i in range(x.shape[0]):\n","        for j in range(y.shape[1]):\n","            row_x = x[i, :]\n","            column_y = y[:, j]\n","            z[i, j] = naive_vector_dot(row_x, column_y)\n","    return z\n","\n","naive_matrix_dot(x, y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tqWa2prIPAUE","executionInfo":{"status":"ok","timestamp":1689217989235,"user_tz":-540,"elapsed":407,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"0b3f7eb1-6a6c-40e3-87bc-5dd6ba85e17c"},"execution_count":86,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[6.24707351, 6.06136336],\n","       [6.23769721, 6.79245551],\n","       [8.5255747 , 8.67806531],\n","       [7.74176417, 7.73321784],\n","       [6.83950134, 7.14651869],\n","       [5.6152786 , 4.83442739],\n","       [6.87143283, 6.86591164],\n","       [8.00304309, 6.61671099],\n","       [8.39386102, 7.7316533 ],\n","       [6.00712725, 6.3438579 ],\n","       [6.40491057, 6.88196096],\n","       [6.9713725 , 5.83968119],\n","       [5.49051799, 4.96638669],\n","       [6.7448047 , 7.55889132],\n","       [6.1724034 , 7.13738752],\n","       [6.6382646 , 5.61656356],\n","       [6.27714765, 5.99411512],\n","       [7.48904996, 6.58466845],\n","       [5.55795951, 6.56757317],\n","       [8.21959887, 7.34835169],\n","       [6.27165481, 7.31114916],\n","       [6.70200967, 6.20377821],\n","       [7.12544941, 6.38463949],\n","       [6.02892287, 4.98213785],\n","       [7.44016235, 6.68770896],\n","       [7.30536016, 6.6386037 ],\n","       [6.24941262, 7.80022751],\n","       [6.45689121, 6.78585584],\n","       [7.16499933, 6.65312623],\n","       [7.78215385, 7.59447581],\n","       [5.89069011, 5.05619054],\n","       [6.76158049, 6.55019307]])"]},"metadata":{},"execution_count":86}]},{"cell_type":"markdown","source":["## 2.3.4 텐서 크기 변환\n","- 텐서의 크기를 변환한다는 것은 특정 크기게 맞게 열과 행을 재배열한다는 뜻임, 당연히 크기가 변환된 텐서는 원래 텐서와 원소 개수가 동일함"],"metadata":{"id":"7Zf4mmGawXPO"}},{"cell_type":"code","source":["x = np.array([[0., 1.],\n","              [2., 3.],\n","              [4., 5.]])\n","\n","print(x.shape, '\\n')\n","\n","x = x.reshape((6,1))\n","print(x, '\\n')\n","\n","x = x.reshape((2,3))\n","print(x, '\\n')\n","\n","# 자주 사용하는 특별한 크기 변환은 전치(transposition)임\n","x = np.zeros((300, 20))\n","x = np.transpose(x)\n","x.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0tK7u74xulAY","executionInfo":{"status":"ok","timestamp":1687918294420,"user_tz":-540,"elapsed":311,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"fcaa3223-db25-483f-b171-6eb2cf436a10"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(3, 2) \n","\n","[[0.]\n"," [1.]\n"," [2.]\n"," [3.]\n"," [4.]\n"," [5.]] \n","\n","[[0. 1. 2.]\n"," [3. 4. 5.]] \n","\n"]},{"output_type":"execute_result","data":{"text/plain":["(20, 300)"]},"metadata":{},"execution_count":107}]},{"cell_type":"markdown","source":["## 2.3.5 텐서 연산의 기하학적 해석\n","- 텐서 연산이 조작하는 텐서의 내용은 어떤 기하학적 공간에 있는 좌표 포인트로 해석될 수 있기 때문에 모든 텐서 연산은 기하학적 해석이 가능함\n","- 벡터 A에 벡터 B를 더하는 것은 점 A를 새로운 위치로 복사하는 동작임\n","- 원래 점 A에서 새로운 위치까지 거리와 방향은 벡터 B에 의해 결정됨\n","- 동일한 벡터 덧셈을 평면에 있는 점 집합(하나의 객체)에 적용하면 새로운 위치에서 전체 객체의 복사본을 만들게 됨\n","- 따라서 텐서 덧셈은 특정 방향으로 특정 양만큼 (객체를 왜곡시키지 않고) 이동하는 행동을 나타냄\n","\n","- 텐서 연산으로 표현할 수 있는 기본적인 기하학적 연산\n","    - 이동(translation)\n","    - 회전(rotation)\n","    - 크기 변경(scaling)\n","    - 기울이기(skewing)\n","\n","<img src = 'https://drive.google.com/uc?id=1bTvb1BrpnrvIZqGHNoMMiDIDnTFcyJxb' height=300 width=500>><br><br>\n","\n","<img src = 'https://drive.google.com/uc?id=1aDhPNJ4FmTEUFqxfb6E6wVI5tmjpc47P' height=300 width=500>><br><br>\n","\n","<img src = 'https://drive.google.com/uc?id=1zt1fwifjH6iCV10fHiL3uzEahLjanlKu' height=300 width=500>><br><br>\n","\n","<img src = 'https://drive.google.com/uc?id=1OD-8NyhdMQvluponFhRQ_hp3SNRo5iHH' height=300 width=500>><br><br>\n","\n","<img src = 'https://drive.google.com/uc?id=1Ceafi4IPvIzqOKKKGn45SwKWzWSLqFMc' height=300 width=500>><br><br>\n","\n","\n","\n","\n","- 선형 변환(linear transform)\n","    - 여기에서 원점을 기준으로 발생하는 변환이 이기에 회적과 크기 변경이 포함됨\n","\n","- 아핀 변환(affine transform)\n","    - 크기 변경, 회전, 이동, 기울기 등을 모두 포함하는 선형 변환임\n","    - (어떤 행렬과 점곱하여 얻는) 선형 변환과 (벡터를 더해 얻는) 이동의 조합임\n","    - 이는 Dense 층에서 수행되는 y = Wx+b 계산과 정확히 일치함\n","    - 활성화 함수를 사용하지 않는 Dense 층은 일종의 아핀 변환 층임\n","\n","<img src = 'https://drive.google.com/uc?id=1CDTtXPFTgDrs4-ypD1feK3H_8kFeV_ez' height=300 width=500>><br><br>\n","\n","- relu 활성화 함수를 사용하는 Dense 층\n","    - 아핀 변환의 중요한 성질 하나는 여러 아핀 변환을 반복해서 적용해도 결국 하나의 아핀 변환이 된다는 것임(따라서 처음에 이 하나의 아핀 변환을 적용할 수 있음)\n","    - 결국 활성화 함수 없이 Dense 층으로만 구성된 다층 신경망은 하나의 Dense 층과 같음\n","    - 하나의 선형 모델이 심층 신경망으로 위장한 것과 같음\n","    - 이것이 relu 같은 활성화 함수가 필요한 이유임\n","    - 활성화 함수 덕분에 Dense 층을 중첩하여 매우 복잡하고 비선형적인 기하학적 변형을 구현하며 심층 신경망에 매우 풍부한 가설 공간을 제공할 수\n","    \n","<img src = 'https://drive.google.com/uc?id=1CDTtXPFTgDrs4-ypD1feK3H_8kFeV_ez' height=300 width=500>><br><br>\n"],"metadata":{"id":"XEPJvYi0xWo4"}},{"cell_type":"markdown","source":["선형 변환, 아핀 변환을 많이 하면 층을 하나 둔 것돠 다를 바 없다.\n","\n","그래서 활성화 함수를 추가적으로 둠으로써 층을 거듭해도 필터링 효과를 올리는 것이다\n","\n","기하학적 변형을 하는 이유는 기계가 좀 더 잘 예측할 수 있게 하기 위하여"],"metadata":{"id":"YArbJuRlxB5e"}},{"cell_type":"markdown","source":["## 2.3.6 딥러닝의 기하학적 해석\n","- 신경망은 전체적으로 텐서 연산의 연결로 구성됨\n","- 그리고 모든 텐서 연산은 입력 데이터의 간단한 기하학적 변환임\n","- 단순한 단계들이 길게 이어져 구현된 신경망을 고차원 공간에서 매우 복잡한 기하학적 변환을 하는 것으로 해석할 수 있음\n","- 예를 들어, 하나는 빨간색이고 다른 하나는 파란색인 2개의 색종이가 있다고 가정하고, 두 장을 겹친 다음 뭉쳐서 작은 공으로 만듦\n","- 이 종이 공이 입력 데이터고 색종이는 분류 문제의 클래스임, 신경망이 해야 할 일은 종기 공을 펼쳐서 두 클래스가 다시 깔끔하게 분리되는 변환을 찾는 것임\n","- 손가락으로 종이 공을 조금씩 펼치는 것처럼 딥러닝을 사용하여 3D 공간에서 간단한 변환들을 연결해서 이를 구현함\n","- 고차원 공간에서 복잡하고 심하게 꼬여 있는 데이터의 매니폴드(매니폴드는 구겨진 종이처럼 하나의 연속적인 표면)에 대한 깔끔한 표현을 찾는 일임\n","- 매니폴드는 국부적으로 저차원의 유클리드 거리로 볼 수 있는 고차원 공간임\n"],"metadata":{"id":"wHCJ2Ogo0px2"}},{"cell_type":"markdown","source":["<font color=red>어려움, 추후 학습</font>\n","\n","# 2.4 신경망의 엔진: 그레이디언트 기반 최적화\n","- 초기에는 가중치 행렬이 작은 난수로 채워져 있음\n","- 피드백 신호에 기초하여 가중치가 점진적으로 조정됨 -> 이런 점진적인 조정 또는 training이 머신 러닝 학습의 핵심임\n","- 단계\n","    - 훈련 샘플 x와 이에 상응하는 타깃 y_true의 배치를 추출\n","    - x를 사용하여 모델을 실행하고(forward pass 단계), 예측 y_pred를 구함\n","    - y_pred와 y_true의 차이를 측정하여 이 배치에 대한 모델의 손실을 계산 (=모델의 손실)\n","    - 배치에 대한 손실이 조금 감소되도록 모델이 모든 가중치를 업데이트함\n","- <font color=red>이 모델은 입력에 정확한 타깃을 매핑하는 것을 학습했음</font>\n","- 위의 단계에서 어려운 부분은 모델의 가중치를 업데이트하는 4단계임\n","\n","## 2.4.1 도함수란?\n","\n","## 2.4.2 텐서 연산의 도함수: 그레이디언트\n","\n","## 2.4.3 확률적 경사 하강법\n","- 미분 가능한 함수가 주어지면 이론적으로 이 함수의 최솟값을 해석적으로 구할 수 있음\n","- 함수의 최솟값은 도함수가 0인 지점임, 따라서 우리가 할 일은 도함수가 0이 되는 지점을 모두 찾고 이 중에서 어떤 포인트의 함수 값이 가장 작은지 확인하는 것임\n","- 신경망에 적용하면 가장 작은 손실 함수의 값을 만드는 가중치의 조합을 해석적으로 찾는 것을 의미함\n","- grad(f(W), W) = 0을 풀면 됨\n","    - 함수 f(W)를 W에 대한 미분한 결과를 나타내는 벡터\n","- 랜덤한 배치 데이터에서 현재 손실 값을 토대로 하여 조금씩 파라미터를 수정함, 미분 가능한 함수를 가지고 있으므로 그레이디언트를 계산하여 단계 4를 효율적으로 구현할 수 있음, 그레이디언트의 반대 방향으로 가중치를 업데이트하면 손실이 매번 조금씩 감소할 것임\n","    1. 훈련 샘플 배치 x와 이에 상응하는 타깃 y_true를 추출\n","    2. x로 모델을 실행하고 예측 y_pred를 구함(정방향 패스)\n","    3. 이 배치에서 y_pred와 y_true 사이의 오차를 측정하여 모델의 손실을 계산\n","    4. 모델의 파라미터에 대한 손실 함수의 그레이디언트를 계산(backward pass)\n","    5. 그레이디언트의 반대 방향으로 파라미터를 조금 이동시킴, 예를 즐어 W -= learning_rate * gradient처럼 하면 배치에 대한 손실이 조금 감소할 것임, 학습률(learning rate)은 경사 하강법 과정의 속도를 조절하는 스칼라 값임\n","- 이것이 바로 mini-batch SGD(stochastic gradient descent) 미니 배치 확률적 경사 하강법임\n","\n","#### 알고리즘 종류\n","- 배치 경사 하강법 - 가용한 모든 데이터를 사용하여 반복 실행(정확하게 업데이트 되지만 많은 비용 발생)\n","- 미니 배치 SGD - 위 아래 극단적인 두 가지 방법의 효율적인 절충안은 적절한 크기의 미니 배치를 사용하는 것임\n","- true SGE - 반복마다 하나의 샘플과 하나의 타깃을 뽑는 것\n","\n","#### 변종들\n","- (업데이트할 다음 가중치를 계산할 때 현재 그레이디언트 값만 보지 않고 이전에 업데이트된 가중치를 여러 가지 다른 방식으로 고려하는 SGD 변종들이 많음)\n","- (이런 변종들을 모두 최적화 방법(optimization method), optimizer라고 부름)\n","- momentum SGD - SGD에 있는 2개의 문제점인 수렴 속도와 지역 최솟값을 해결함\n","- Adagrad\n","- RMSProp\n"],"metadata":{"id":"E1rAPvs-0rlJ"}},{"cell_type":"markdown","source":["\n","지역 최솟값(Local minimum)과 안장점(Saddle point)은 함수의 극소점을 나타내는 용어입니다.\n","\n","지역 최솟값은 주어진 함수에서 특정 지역에서만 최소값을 가지는 점을 말합니다. 다시 말해, 주변 이웃보다 더 작은 함수값을 가지지만, 전역적으로는 최소값이 아닐 수 있습니다. 함수의 전역 최소값과 구별되는 특징은 지역적으로만 유효하다는 점입니다. 함수의 형태에 따라 지역 최솟값이 여러 개 존재할 수 있습니다.\n","\n","안장점은 주어진 함수에서 특정 지점에서 극소점이 아니지만 극값을 가지는 점을 말합니다. 이는 함수의 그래디언트가 0이지만, 두 개 이상의 방향으로 곡면이 형성되어 있는 경우입니다. 즉, 안장점에서는 한 방향으로는 최소값, 다른 방향으로는 최대값을 가지지만 전체적으로는 극값을 가지는 점입니다.\n","\n","지역 최솟값은 지역적으로만 작은 값을 가지는 점이며, 안장점은 극값을 가지는 점으로서 특정 방향으로는 최소값, 다른 방향으로는 최대값을 가집니다. 이러한 차이점으로 인해 최적화 알고리즘 등에서 지역 최솟값을 탈출하고 전역 최솟값을 찾는 것이 중요하며, 안장점은 함수의 형태와 최적화 알고리즘의 동작에 영향을 줄 수 있습니다."],"metadata":{"id":"OVyRm19mvGIE"}},{"cell_type":"markdown","source":["#### momentum 개념\n","- 지역 최솟값 문제\n","    - 그 지점 근처에서는 왼쪽으로 이동해도 손실이 증가하고, 오른쪽으로 이동해도 손실이 증가함, 대상 파라미터가 작은 학습률을 가진 SGD로 최적화되었다면 최적화 과정이 전역 최솟값으로 향하지 못하고 이 지역 최솟값에 갇히게 됨\n","- 지역 최솟값 문제 해결\n","    - 물리학에서 영감을 얻은 모멘텀을 사용하여 이 문제를 피할 수 있음, 여기에서 최적화 과정을 손실 곡선 위로 작은 공을 굴이는 것으로 생각하면 쉽게 이해할 수 있음, 모멘텀이 충분하면 공이 골짜기에 갇히지 않고 전역 회솟값에 도달할 것임, 모멘텀은 현재 기울기 값(현재 가속도)뿐만 아니라 (과거의 가속도로 인한) 현재 속도를 함께 고려하여 각 단계에서 공을 움직임, 실전에 적용할 때는 현재 그레이디언트 값뿐만 아니라 이전에 업데이트한 파라미터에 기초하여 파라미터 w를 업데이트함\n","- 경사 하강법 최적화에 관성을 도입하여 이전 단계에서 계산된 그레이디언트 방향을 유지하고 더 빠른 수렴을 도와주는 기법\n","- 이전 단계의 속도인 'past_velocity'와 현재 단계에서 계산된 그레이디언트를 고려하여 새로운 속도 'velocity'를 계산함, 이를 통해 그레이디언트의 방향과 크기를 고려한 업데이트가 이루어짐\n","\n","```\n","# 모멘텀을 두 번 반복하는 Nesterov Momentum 알고리즘 구현한 것임\n","# 기본 모멘텀은 여섯 번째 줄을 w = w + velocity로 바꿔주면 됨\n","\n","past_velocity = 0.     # 이전 단계에서 계산된 속도\n","momentum = 0.1    # 모멘텀 상수\n","while loss > 0.01:    # 최적화 반복 루프\n","    w, loss, gradient * past_velocity - learning_rate * gradient\n","    velocity = momentum * past_velocity - learning_rate * gradient\n","    w = w + momentum * velocity = learning_rate * gradient\n","    past_velocity = celocity\n","    update_parameter(w)\n","```\n","\n","```\n","# 사용 예\n","from tensorflow.keras import optimizers\n","\n","sgd = optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True)\n","network.compile(optimizer=sgd, ...)\n","\n","```\n","\n","\n","\n"],"metadata":{"id":"_UpWtQzjqk80"}},{"cell_type":"markdown","source":["## 2.4.4 도함수 연결: 역전파 알고리즘\n","\n","#### 연쇄 법칙\n","- 역전파는 (덧셈, 렐루, 텐서 곱셈 같은) 간단한 연산의 도함수를 사용해서 이런 기초적인 연산을 조합한 복잡한 연산의 그레이디언트를 쉽게 계산하는 방법임\n","- 결정적으로 신경망은 서로 연결된 많은 텐서 연산으로 구성됨, 이런 연산은 간단하고 해당 도함수가 알려져 있음\n","- 함수 f와 g의 도함수를 알고 있다면 fg의 도함수를 계산할 수 있음, 중간에 함수를 더 추가하면 chain처럼 보이기 때문에 연쇄 법칙(chain rule)이라고 부름\n","    - 연쇄 법칙 - 미분의 연쇄적인 성질을 나타내는 법칙으로, 합성 함수의 도함수(미분)를 구하는 방법을 제공함\n","- 신경망의 그레이디언트 값을 계산하는 데 이 연쇄 법칙을 적용하는 것이 역전파 알고리즘임\n","- 신경망의 그레이디언트 값을 계산하는 데 이 연쇄 법칙을 적용하는 것이 역전파 알고리즘임\n","\n","#### 계산 그래프를 활용한 자동 미분\n","<img src = 'https://drive.google.com/uc?id=11ZPAV_hR0Wh56Dk5eY9x4lI-FvxAMEFg' height=500 width=200>><br><br>\n"],"metadata":{"id":"mytCAdtl1IgX"}},{"cell_type":"markdown","source":["### 텐서플로와 그레이디언트 테이프 (GradientTape)\n","- 텐서플로의 강력한 자동 미분 기능을 활용할 수 있는 API\n","- 이 API는 파이썬의 with문과 함께 사용하여 해당 코드 블록 안의 모든 텐서 연산을 계산 그래프 형태로 기록함\n","- 그다음 이 그래프를 사용해서 (tf.Variable 클래스의 인스턴스인) 변수 또는 변수 집합에 대한 어떤 출력의 그레이디언트도 계산할 수 있음\n","tf.Variable은 변경 가능한(mutable) 상태를 담기 위한 특별한 종류의 텐서임, 예를 들어 신경망의 가중치는 항상 rf.Variable의 인스턴스임\n","\n","### TensorFlow를 사용하여 변수 x에 대한 식 y = 2 * x + 3의 그래디언트(기울기)를 계산하고 tape.gradient()를 사용하여 y에 대한 x의 그래디언트를 계산. 이를 통해 x의 값을 조정할 때 y가 어떻게 변화하는지를 알 수 있으며, 이는 모델의 최적화와 역전파 알고리즘에서 매우 유용.\n","- TensorFlow 변수 x를 생성합니다. tf.zeros((2, 2))를 사용하여 크기가 2x2이고 모든 요소가 0인 행렬로 초기화\n","- tf.GradientTape()를 사용하여 GradientTape 컨텍스트를 생성하고 tape를 사용하여 연산을 기록\n","- y = 2 * x + 3의 연산을 수행하고 결과를 변수 y에 저장. 이 때, TensorFlow의 브로드캐스팅(broadcasting) 기능을 사용하여 x의 각 요소에 2를 곱하고 3을 더함.\n","- tape.gradient()를 사용하여 y에 대한 x의 그래디언트를 계산. 이를 통해 y를 x에 대해 미분한 결과, 즉 y에 대한 x의 기울기를 구한다. tape.gradient()의 첫 번째 인자로는 그래디언트를 계산하고자 하는 결과값(y)을 전달하고, 두 번째 인자로는 그래디언트를 계산하고자 하는 변수(x)를 전달.\n","- grad_of_y_wrt_x에는 y에 대한 x의 그래디언트가 저장된다."],"metadata":{"id":"OHQ1r6SH4as1"}},{"cell_type":"markdown","source":[],"metadata":{"id":"MCehRzEe37u_"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","x = tf.Variable(0.)    # 초깃값 0으로 스칼라 변수를 생성함\n","with tf.GradientTape() as tape:    # GradientTape 블록을 시작함\n","    y = 2 * x + 3    # 이 블록 안에서 변수에 텐서 연산을 적용함\n","grad_of_y_wrt_x = tape.gradient(y, x)    # tape를 사용해서 변수 x에 대한 출력 y의 그레이디언트를 계산함"],"metadata":{"id":"D79MFdzt4XCG","executionInfo":{"status":"ok","timestamp":1689230352414,"user_tz":-540,"elapsed":6043,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# GradientTape를 다차원 텐서와 함께 사용할 수 있음\n","\n","x = tf.Variable(tf.zeros((2,2)))    # 크기가 (2,2)고 초깃값이 모두 0인 변수를 생성\n","with tf.GradientTape() as tape:\n","    y = 2 * x + 3\n","\n","grad_of_y_wrt_x = tape.gradient(y, x)"],"metadata":{"id":"I8oKael847I2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 변수 리스트의 그레이디언트를 계산할 수도 있음\n","\n","W = tf.Variable(tf.random.uniform((2, 2)))\n","b = tf.Variable(tf.zeros((2,)))\n","x = tf.random.uniform((2, 2))\n","with tf.GradientTape() as tape:\n","    y = tf.matmul(x, W) + b    # matmul은 텐서플로의 점곱 함수임\n","grad_of_y_wrt_W_and_b = tape.gradient(y, [W, b])    # grad_of_y_wrt_and_b는 2개의 텐서를 담은 리스트임, 각 텐서는 W, b와 크기가 같음"],"metadata":{"id":"5_U4dphO5abi","executionInfo":{"status":"ok","timestamp":1689234232109,"user_tz":-540,"elapsed":4,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# 가중치 행렬임\n","grad_of_y_wrt_W_and_b    # y의 각 원소가 W의 해당 위치에 대한 그레이디언트 값을 나타냄\n","                         # y에 대한 b의 그레이디언트임"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D3zcrwtb54HL","executionInfo":{"status":"ok","timestamp":1687920679446,"user_tz":-540,"elapsed":489,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"12aaf722-9fbf-4710-c9cc-b88a685bc07f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n"," array([[0.4641074, 0.4641074],\n","        [1.291969 , 1.291969 ]], dtype=float32)>,\n"," <tf.Tensor: shape=(2,), dtype=float32, numpy=array([2., 2.], dtype=float32)>]"]},"metadata":{},"execution_count":114}]},{"cell_type":"markdown","source":["# 2.5 첫 번째 예제 다시 살펴보기\n","- 층이 서로 연결되어 모델을 구성\n","- 모델은 입력 데이터를 예측으로 매핑함(y_pred)\n","- 그다음 손실 함수가 이 예측과 타깃을 비교하여 손실 값을 만듦 (즉, 모델의 예측이 기대한 것에 얼마나 잘 맞는지 측정함)\n","- 옵티마이저는 이 손실 값을 사용하여 모델의 가중치를 업데이트함\n","\n","<img src = 'https://drive.google.com/uc?id=11kHsXZQr4trkopUl9OLr2VMelxVUcygs' height=350 width=400>\n"],"metadata":{"id":"LLOjrvVS6qXX"}},{"cell_type":"markdown","source":["#### 옵티마이저\n","- 모델의 학습 과정을 통제하고, 모델의 성능을 개선하는 역할\n","- 손실 함수 (또는 비용 함수)를 최소화하는 파라미터를 찾는 과정이며, 이 과정은 최적화 (Optimization)라고 함\n","- 옵티마이저\n","  - 확률적 경사 하강법 (SGD): 가장 기본적인 옵티마이저로, 각 훈련 단계에서 하나의 데이터 포인트 (또는 작은 배치)에 대한 그래디언트를 계산하여 모델 파라미터를 업데이트\n","  - 모멘텀: 경사 하강법에 '관성' 개념을 추가하여, 최적화 과정이 수렴을 가속화하고 지역 최솟값에서 벗어나는 데 도움\n","  - AdaGrad: 학습률이 각 파라미터에 따라 다르게 적용되는 적응형 학습률을 사용합니다. 이는 자주 등장하지 않는 피처에 높은 학습률을 할당하는 데 도움\n","  - RMSProp: AdaGrad의 문제점인 학습률이 너무 빨리 감소하는 문제를 해결한 방법\n","  - Adam (Adaptive Moment Estimation): 모멘텀과 RMSProp의 아이디어를 결합한 옵티마이저로, 적응형 학습률과 관성 개념을 모두 사용"],"metadata":{"id":"gcRWT0yXwcCH"}},{"cell_type":"markdown","source":["#### 손실 함수 (Loss Function)\n","- 머신러닝 모델의 예측 출력이 실제 값과 얼마나 잘 일치하는지를 측정하는 방법\n","- 실 함수는 모델의 성능을 수치화하며, 이를 통해 모델의 파라미터를 최적화하는 데 사용\n","- 유형\n","  - 평균 제곱 오차 (Mean Squared Error, MSE): 회귀 문제에서 가장 일반적으로 사용되는 손실 함수. 실제 값과 모델의 예측 값 사이의 차이를 제곱한 값의 평균을 계산\n","  - 크로스 엔트로피 (Cross-Entropy): 분류 문제에서 일반적으로 사용되는 손실 함수. 모델의 예측 확률 분포와 실제 값의 분포 사이의 차이를 측정\n","  - sparse_categorical_crossentropy는 크로스 엔트로피 손실 함수의 한 형태로, 다중 클래스 분류 문제에서 주로 사용\n","  - 힌지 손실 (Hinge Loss): 서포트 벡터 머신 (SVM)과 같은 알고리즘에서 사용\n","  - 로그 손실 (Log Loss): 이진 분류 문제에서 사용되며, 예측 확률을 직접적으로 반영"],"metadata":{"id":"BRkB_TqtwcF9"}},{"cell_type":"markdown","source":["dense - 빽빽한 (=fully connected or fully connected layer)\n","\n","뉴런은 가중치(Weight)와 편향(Bias)을 가지고\n","\n","가중치 텐서 - 인공 신경망에서 각 연결의 가중치를 저장하는 다차원 배열"],"metadata":{"id":"QUn902Ac-E2v"}},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n"," (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","# 훈련을 시작하기 전에 데이터를 모델에 맞는 크기로 바꾸고 모든 값을 0과 1 사이로 스케일을 조정함\n","# 신경망 모델에 입력으로 사용하기 위해서는 이미지 데이터를 1차원 형태로 변환해야 함\n","train_images = train_images.reshape((60000, 28 * 28))    # 이미지 데이터를 1차원으로 펼치는 역할\n","train_images = train_images.astype('float32') / 255\n","test_images = test_images.reshape((10000, 28 * 28))\n","test_images = test_images.astype('float32') / 255\n","\n","# 모델\n","# sequential\n","# 연속적인 (딥러닝에서 입력 데이터를 받아 처리하고 출력을 다음 층으로 전달함,\n","# 이렇게 순서대로 연결된 층들은 데이터가 입력에서 출력 방향으로 흐르는 구조를 가지며, 이러한 구조에서 이 용어가 사용됨)\n","# 2개의 Dense 층이 연결되어 있고 각 층은 가중치 텐서를 포함하여 입력 데이터에 대한 몇 개의 간단한 텐서 연산을 적용함,\n","# 층의 속성인 가중치 텐서는 모델이 정보를 저장하는 곳임\n","model = keras.Sequential([\n","    layers.Dense(512, activation='relu'),\n","    layers.Dense(10, activation='softmax')\n","])\n","\n","# 모델을 컴파일하는 단계\n","# optimizer - 모델이 훈련하는 동안 가중치를 업데이트하는 알고리즘을 지정하는데 사용\n","# rmsprop - 주로 경사 하강법이 사용되며, rmsprop는 경사 하강법 알고리즘 중 하나임\n","# optimizer의 기준이 되는 것이 손실 함수\n","\n","# sparse_categorical_crossentropy\n","# 희소 범주형 크로스 엔트로피\n","# 분류 문제에서 주로 사용되는 손실 함수 중 하나,\n","# 가중치 텐서를 학습하기 위한 피드백 신호로 사용되며 훈련하는 동안 최소화됨, 미니 배치 확률적 경사 하강법을 통해 손실이 감소됨\n","# 경사 하강법을 적용하는 구체적인 방식은 첫 번째 매개변수로 전달된 rmsprop 옵티마이저에 의해 결정됨\n","# 정수 레이블을 가진 데이터에 적합함\n","\n","model.compile(optimizer='rmsprop',\n","              loss='sparse_categorical_crossentropy',\n","              metrics='accuracy')\n","\n","# 마지막으로 훈련 반복\n","# 모델이 128개의 샘플의 미니 배치로 훈련 데이터를 다섯 번 반복함(전체 훈현 데이터에 수행되는 각 반복을 에포크라고 함),\n","# (미적분의 연쇄 법칙에서 파생된 역전파 알고리즘을 사용하여) 각 배치에서 모델이 가중치에 대한 손실의 그레이디언트를 계산함\n","# 그다음 배치에서 손실 값을 감소시키는 방향으로 가중치를 이동시킴\n","# 에포크마다 469번의 업데이트, 다섯 번의 에포크 동안 모델은 2,345번의 그레이디언트 업데이트를 수행함\n","# 훈련 데이터셋 60,000 = 128 * 469\n","# batch - 전체 데이터셋을 작은 일부 그룹으로 나누는 것을 의미함, 일반적으로 딥러닝 모델은 한 번에 모든 데이터를 처리하지 않고,\n","# 작은 배치로 나누어서 처리함 (메모리 효율성, 계산 속도-병렬처리, 일반화 성능-데이터의 다양성)\n","model.fit(train_images, train_labels, epochs=5, batch_size=128)"],"metadata":{"id":"6-i6_gCM6sxF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.5.1 텐서플로를 사용하여 첫 번째 예제를 밑바닥부터 다시 구현하기\n","\n","dot, matmul - 둘 다 행렬의 곱셈 연산을 수행하는 함수, 차이는 있음\n","\n","matmul과 dot은 둘 다 행렬의 곱셈 연산을 수행하는 함수입니다. 그러나 두 함수에는 약간의 차이가 있습니다.\n","\n","matmul: 행렬의 곱셈 연산을 수행합니다. tf.matmul(a, b)는 a와 b의 행렬 곱을 계산합니다. a와 b는 2D 이상의 텐서일 수 있으며, 행렬의 크기에 맞는 곱셈을 수행합니다. 예를 들어, a의 shape이 (m, n)이고 b의 shape이 (n, p)이면, 결과는 shape이 (m, p)인 행렬이 됩니다.\n","\n","dot: 행렬의 곱셈 연산을 수행합니다. tf.tensordot(a, b, axes)는 a와 b의 텐서 곱을 계산합니다. axes 인수를 통해 곱셈이 수행될 축을 지정할 수 있습니다. 만약 axes를 지정하지 않으면, a와 b의 마지막 축에서의 내적을 수행합니다.\n","\n","따라서 output = activation(dot(W, input) + b)는 입력 input과 가중치 W의 내적을 계산하고, 편향 b를 더한 후, 활성화 함수인 activation을 적용하는 연산을 수행합니다. 이때, dot 함수는 matmul과 유사한 역할을 수행하며, 마지막 축에서의 내적을 계산합니다."],"metadata":{"id":"z2IkeJy2DV18"}},{"cell_type":"markdown","source":["#### 가중치 vs 그래디언트\n","가중치는 신경망의 출력을 결정하는 파라미터이며, 그래디언트는 이러한 가중치를 어떻게 조정할지를 결정하는 방향성을 제공하는 지표\n","- 가중치는 각 입력 특성이 출력에 미치는 영향의 정도를 나타냅니다. 가중치는 학습 과정에서 최적화되며, 초기에는 일반적으로 임의의 값으로 설정되고, 학습 데이터를 통해 그래디언트를 계산하고 가중치를 업데이트함으로써 점진적으로 개선\n","- 그래디언트(Gradient): 그래디언트는 가중치가 변할 때 손실 함수가 어떻게 변하는지를 나타내는 지표. 그래디언트는 손실 함수의 편미분으로 계산되며, 이는 각 가중치에 대한 손실의 변화율을 나타낸다. 그래디언트는 가중치를 어떻게 업데이트할지를 결정하는데 사용되며, 손실을 줄이는 방향으로 가중치를 조정하는데 도움이 되며 그래디언트가 0인 경우, 해당 가중치는 손실에 미치는 영향이 없거나, 손실을 최소화하는 최적의 값에 도달했음을 의미"],"metadata":{"id":"IiHcGtKXzgVv"}},{"cell_type":"markdown","source":["#### 단순한 Dense 클래스\n","- W와 b - 모델 파라미터\n","- activation - 각 원소에 적용되는 함수(relu, softmax)\n","- 2개의 텐서플로 변수 W와 b를 만들고 __call__() 메서드에서 앞서 언급한 변환을 적용\n","```\n","output = activation(dot(W, input) + b)\n","```\n","\n","\n"],"metadata":{"id":"6N1BlRErRIZh"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","class NaiveDense:    # 간단한 기본적인 Dense 층 구현하는 사용자 함수를 의미함\n","    def __init__(self, input_size, output_size, activation):\n","        self.activation = activation\n","\n","        w_shape = (input_size, output_size)    # 랜덤한 값으로 초기화된(input_size, output_size) 크기의 행렬 W를 만듦\n","        w_initial_value = tf.random.uniform(w_shape, minval=0, maxval=1e-1)    # 균일 분포에서 난수 생성, maxval = 0.1\n","        self.W = tf.Variable(w_initial_value)\n","\n","        b_shape = (output_size,)    # 0으로 초기화된(output_size) 크기의 벡터 b를 만듦\n","        b_initial_value = tf.zeros(b_shape)\n","        self.b = tf.Variable(b_initial_value)\n","\n","    def __call__(self, inputs):    # 입력 데이터를 받아 정방향 패스를 수행하여 변환을 해주는 역할, 정방향 패스를 수행함\n","        return self.activation(tf.matmul(inputs, self.W) + self.b)    # 계산 결과에 self.activation 함수를 적용하여 변환된 값을 반환함\n","\n","    @property    # 클래스 내에서 메서드를 속성(property)으로 정의하는 파이썬 데코레이터임\n","    def weights(self):    # 층의 가중치를 추출하기 위한 메서드, weights 메서드를 속성으로 정의함으로써, 해당 속성에 접근하는 것처럼 호출할 수 있게 됨\n","        return [self.W, self.b]"],"metadata":{"id":"typ2XeG7C-Y2","executionInfo":{"status":"ok","timestamp":1689236480566,"user_tz":-540,"elapsed":472,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["#### 단순한 Sequential 클래스\n","- NaiveSequential 클래스를 만들어 층 연결하기\n","- 층의 리스트를 받고 __call__() 메서드에서 입력을 사용하여 층을 순서대로 호출함\n","- 층의 파라미터를 쉽게 구할 수 있도록 weights 속성을 제공함"],"metadata":{"id":"VWDNV9JtQ8l7"}},{"cell_type":"code","source":["class NaiveSequential:\n","    def __init__(self, layers):\n","        self.layers = layers\n","\n","    def __call__(self, inputs):\n","        x = inputs\n","        for layer in self.layers:\n","           x = layer(x)\n","        return x\n","\n","    @property\n","    def weights(self):\n","       weights = []\n","       for layer in self.layers:\n","           weights += layer.weights\n","       return weights"],"metadata":{"id":"SPIimVruQA2L","executionInfo":{"status":"ok","timestamp":1689236564801,"user_tz":-540,"elapsed":462,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["model = NaiveSequential([\n","    NaiveDense(input_size=28 * 28, output_size=512, activation=tf.nn.relu),    # neural network\n","    NaiveDense(input_size=512, output_size=10, activation=tf.nn.softmax)\n","])\n","assert len(model.weights) == 4    # 층이 2개라 w,b가 각각 2개씩 총 4개임"],"metadata":{"id":"g3HxxNw9QK4c","executionInfo":{"status":"ok","timestamp":1689237198124,"user_tz":-540,"elapsed":463,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["#### 배치 제너레이터\n","- MNIST 데이터를 미니 배치로 순회"],"metadata":{"id":"_1CF5STDR2sa"}},{"cell_type":"code","source":["# 배치 제너레이터\n","import math\n","\n","class BatchGenerator:\n","    def __init__(self, images, labels, batch_size=128):\n","        assert len(images) == len(labels)\n","        self.index = 0\n","        self.images = images\n","        self.labels = labels\n","        self.batch_size = batch_size\n","        self.num_batches = math.ceil(len(images) / batch_size)\n","\n","    def next(self):\n","        images = self.images[self.index : self.index + self.batch_size]\n","        labels = self.labels[self.index : self.index + self.batch_size]\n","        self.index += self.batch_size\n","        return images, labels"],"metadata":{"id":"b1bCaY8PQNdL","executionInfo":{"status":"ok","timestamp":1689237201325,"user_tz":-540,"elapsed":4,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## 2.5.2 훈련 스텝 실행하기\n","1. 배치에 있는 이미지에 대해 모델의 예측을 계산함\n","2. 실제 레이블을 사용하여 이 예측의 손실 값을 계산함\n","3. 모델 가중치에 대한 손실의 그레이디언트를 계산함\n","    - 그레이디언트 계산을 위해 GradientTape 객체 사용\n","4. 이 그레이디언트의 반대 방향으로 가중치를 조금 이동함\n"],"metadata":{"id":"C9QnD9qVQRVz"}},{"cell_type":"code","source":["def one_training_step(model, images_batch, labels_batch):\n","    with tf.GradientTape() as tape:\n","        predictions = model(images_batch)\n","        per_sample_losses = tf.keras.losses.sparse_categorical_crossentropy(\n","            labels_batch, predictions)\n","        average_loss = tf.reduce_mean(per_sample_losses)\n","    gradients = tape.gradient(average_loss, model.weights)\n","    update_weights(gradients, model.weights)\n","    return average_loss"],"metadata":{"id":"qqS2OnC5QQZL","executionInfo":{"status":"ok","timestamp":1689237205917,"user_tz":-540,"elapsed":2,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["# update_weights 함수에 해당하는 '가중치 업데이터' 단계의 목적은 이 배치의 손실을 감소시키기 위한 방향으로 가중치를 '조금' 이동하는 것임\n","# 이동의 크기는 '학습률'에 의해 결정됨, 학습률은 일반적으로 작은 값임\n","# update_weithts 함수를 구현하는 가장 간단한 방법은 각 가중치에서 gradient * learning_rate를 빼는 것임\n","learning_rate = 1e-3\n","\n","def update_weights(gradients, weights):\n","    for g, w in zip(gradients, weights):\n","        w.assign_sub(g * learning_rate)"],"metadata":{"id":"Z28EuhNtQU2M","executionInfo":{"status":"ok","timestamp":1689237215943,"user_tz":-540,"elapsed":461,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# 실제로는 이런 가중치 업데이트 단계를 수동으로 구현하는 경우는 거의 없음, 그 대신 다음과 같이 케라스의 Optimizer 인스턴스를 사용함\n","from tensorflow.keras import optimizers\n","\n","optimizer = optimizers.SGD(learning_rate=1e-3)\n","\n","def update_weights(gradients, weights):\n","    optimizer.apply_gradients(zip(gradients, weights))"],"metadata":{"id":"XMeop76CQWPE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 2.5.3 전체 훈련 루프\n","- 훈련 에포크 하나는 단순히 훈련 데이터의 각 배치에 대한 훈련 스텝을 반복하는 것임, 전체 훈련 루프(loop)는 단순히 에포크의 반복임"],"metadata":{"id":"lEO1kW2JQXeU"}},{"cell_type":"code","source":["def fit(model, images, labels, epochs, batch_size=128):\n","    for epoch_counter in range(epochs):\n","        print(f\"에포크 {epoch_counter}\")\n","        batch_generator = BatchGenerator(images, labels)\n","        for batch_counter in range(batch_generator.num_batches):\n","            images_batch, labels_batch = batch_generator.next()\n","            loss = one_training_step(model, images_batch, labels_batch)\n","            if batch_counter % 100 == 0:\n","                print(f\"{batch_counter}번째 배치 손실: {loss:.2f}\")"],"metadata":{"id":"AE0vHT8ZQj17","executionInfo":{"status":"ok","timestamp":1689237220414,"user_tz":-540,"elapsed":2,"user":{"displayName":"박주경","userId":"06694313831384541311"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.datasets import mnist\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","train_images = train_images.reshape((60000, 28 * 28))\n","train_images = train_images.astype(\"float32\") / 255\n","test_images = test_images.reshape((10000, 28 * 28))\n","test_images = test_images.astype(\"float32\") / 255\n","\n","fit(model, train_images, train_labels, epochs=10, batch_size=128)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nfZTrRGrQlGz","executionInfo":{"status":"ok","timestamp":1689237296116,"user_tz":-540,"elapsed":73411,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"c17e781e-c2c3-42e7-cb79-15febfb1dc00"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n","에포크 0\n","0번째 배치 손실: 6.14\n","100번째 배치 손실: 2.21\n","200번째 배치 손실: 2.18\n","300번째 배치 손실: 2.10\n","400번째 배치 손실: 2.22\n","에포크 1\n","0번째 배치 손실: 1.92\n","100번째 배치 손실: 1.86\n","200번째 배치 손실: 1.80\n","300번째 배치 손실: 1.72\n","400번째 배치 손실: 1.83\n","에포크 2\n","0번째 배치 손실: 1.60\n","100번째 배치 손실: 1.56\n","200번째 배치 손실: 1.49\n","300번째 배치 손실: 1.43\n","400번째 배치 손실: 1.51\n","에포크 3\n","0번째 배치 손실: 1.34\n","100번째 배치 손실: 1.33\n","200번째 배치 손실: 1.24\n","300번째 배치 손실: 1.22\n","400번째 배치 손실: 1.28\n","에포크 4\n","0번째 배치 손실: 1.15\n","100번째 배치 손실: 1.15\n","200번째 배치 손실: 1.04\n","300번째 배치 손실: 1.06\n","400번째 배치 손실: 1.11\n","에포크 5\n","0번째 배치 손실: 1.00\n","100번째 배치 손실: 1.01\n","200번째 배치 손실: 0.90\n","300번째 배치 손실: 0.93\n","400번째 배치 손실: 0.99\n","에포크 6\n","0번째 배치 손실: 0.89\n","100번째 배치 손실: 0.90\n","200번째 배치 손실: 0.80\n","300번째 배치 손실: 0.84\n","400번째 배치 손실: 0.90\n","에포크 7\n","0번째 배치 손실: 0.81\n","100번째 배치 손실: 0.82\n","200번째 배치 손실: 0.72\n","300번째 배치 손실: 0.77\n","400번째 배치 손실: 0.83\n","에포크 8\n","0번째 배치 손실: 0.74\n","100번째 배치 손실: 0.75\n","200번째 배치 손실: 0.66\n","300번째 배치 손실: 0.72\n","400번째 배치 손실: 0.78\n","에포크 9\n","0번째 배치 손실: 0.69\n","100번째 배치 손실: 0.69\n","200번째 배치 손실: 0.61\n","300번째 배치 손실: 0.67\n","400번째 배치 손실: 0.74\n"]}]},{"cell_type":"markdown","source":["## 2.5.4 모델 평가하기\n","- 테스트 이미지에 대한 예측에 argmax 함수를 적용하고, 예상 레이블과 비교하여 모델을 평가"],"metadata":{"id":"Qgx7YRULQovn"}},{"cell_type":"code","source":["import numpy as np\n","\n","predictions = model(test_images)\n","predictions = predictions.numpy()\n","predicted_labels = np.argmax(predictions, axis=1)\n","matches = predicted_labels == test_labels\n","print(f\"정확도: {matches.mean():.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NbQGA5MfQmUi","executionInfo":{"status":"ok","timestamp":1689237313937,"user_tz":-540,"elapsed":487,"user":{"displayName":"박주경","userId":"06694313831384541311"}},"outputId":"5e56a98b-eb9a-4995-c89e-459dc447eb51"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["정확도: 0.81\n"]}]},{"cell_type":"markdown","source":["# 2.6 요약\n","- 텐서는 현대 머신 러닝 시스템의 기초임, 텐서는 dtype, ndim, shape 속성을 제공함\n","- 텐서 연산(덧셈, 텐서 곱셈, 원소별 곱셈 등)을 통해 수치 텐서를 조작할 수 있음, 이런 연산은 기하학적 변형을 적용하는 것으로 이해할 수 있음, 일반적으로 딥러닝의 모든 것은 기하학적으로 해석할 수 있음\n","- 딥러닝 모델은 가중치 텐서를 매개변수로 받는 간단한 텐서 연산을 연결하여 구성됨, 모델의 가중치는 모델이 학습한 '지식'을 저장하는 곳임\n","- 학습(learning)은 훈련 데이터 샘플과 그에 상응하는 타깃이 주어졌을 때 손실 함수를 최소화하는 모델의 가중치 값을 찾는 것을 의미함\n","- 데이터 샘플과 타깃의 배치를 랜덤하게 뽑고 이 배치에서 모델 파라미터에 대한 손실의 그레이디언트를 계산함으로써 학습이 진행됨, 모델의 파라미터는 그레이디언트의 반대 방향으로 조금씩(학습률에 의해 정의된 크기만큼) 움직임, 이를 미니 배치 경사 하강법이라고 부름\n","- 전체 학습 과정은 신경망에 있는 모든 텐서 연산이 미분 가능하기 때문에 가능함, 따라서 현재 파라미터와 배치 데이터를 그레이디언트 값에 매핑해 주는 그레이디언트 함수를 구성하기 위해 미분의 연쇄 법칙을 사용할 수 있음, 이를 역전파라고 부름\n","- 이어지는 장에서 자주 보게 될 두 가지 핵심 개념은 손실과 옵티마이저임, 이 두 가지는 모델에 데이터를 주입하기 전에 정의되어야 함\n","- 손실은 훈련하는 동안 최소화해야 할 양이므로 해결하려는 문제의 성공을 측정하는 데 사용함\n","- 옵티마이저는 손실에 대한 그레이디언트가 파라미터를 업데이트하는 정확한 방식을 정의함, 예를 들어 RMSProp 옵티마이저, 모멘텀을 사용한 SGD 등임"],"metadata":{"id":"8F3gnSbwQvrr"}}]}